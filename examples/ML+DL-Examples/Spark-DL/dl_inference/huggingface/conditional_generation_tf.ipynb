{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "777fc40d",
   "metadata": {},
   "source": [
    "# PySpark Huggingface Inferencing\n",
    "## Conditional generation\n",
    "\n",
    "From: https://huggingface.co/docs/transformers/model_doc/t5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c79ac4-bf25-421e-b55e-020d6d9e15d5",
   "metadata": {},
   "source": [
    "### Using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f0dbf3-712b-4c58-85eb-261ce15bb2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rishic/anaconda3/envs/spark-dl-tf/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-09-25 16:46:50.339621: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-25 16:46:50.363834: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-25 16:46:50.372743: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-25 16:46:50.398737: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-25 16:46:51.348243: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFT5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2684fb41-9467-40c0-9d7e-a1cc867c5a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 16:46:59.902638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31135 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:34:00.0, compute capability: 7.0\n",
      "2024-09-25 16:46:59.917658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 31135 MB memory:  -> device: 1, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:36:00.0, compute capability: 7.0\n",
      "2024-09-25 16:46:59.919504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 31135 MB memory:  -> device: 2, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:39:00.0, compute capability: 7.0\n",
      "2024-09-25 16:46:59.921301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 31135 MB memory:  -> device: 3, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2024-09-25 16:46:59.923199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 31135 MB memory:  -> device: 4, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:57:00.0, compute capability: 7.0\n",
      "2024-09-25 16:46:59.925397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 31135 MB memory:  -> device: 5, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:59:00.0, compute capability: 7.0\n",
      "2024-09-25 16:46:59.938340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 31135 MB memory:  -> device: 6, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5c:00.0, compute capability: 7.0\n",
      "2024-09-25 16:46:59.960849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 31135 MB memory:  -> device: 7, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5e:00.0, compute capability: 7.0\n",
      "2024-09-25 16:46:59.984840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:8 with 31135 MB memory:  -> device: 8, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b7:00.0, compute capability: 7.0\n",
      "2024-09-25 16:47:00.008835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:9 with 31135 MB memory:  -> device: 9, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b9:00.0, compute capability: 7.0\n",
      "2024-09-25 16:47:00.032805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:10 with 31135 MB memory:  -> device: 10, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:bc:00.0, compute capability: 7.0\n",
      "2024-09-25 16:47:00.056825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:11 with 31135 MB memory:  -> device: 11, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:be:00.0, compute capability: 7.0\n",
      "2024-09-25 16:47:00.080815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:12 with 31135 MB memory:  -> device: 12, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e0:00.0, compute capability: 7.0\n",
      "2024-09-25 16:47:00.104794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:13 with 31135 MB memory:  -> device: 13, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e2:00.0, compute capability: 7.0\n",
      "2024-09-25 16:47:00.129758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:14 with 31135 MB memory:  -> device: 14, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e5:00.0, compute capability: 7.0\n",
      "2024-09-25 16:47:00.152802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:15 with 31135 MB memory:  -> device: 15, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e7:00.0, compute capability: 7.0\n",
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-small\")\n",
    "model = TFT5ForConditionalGeneration.from_pretrained(\"google-t5/t5-small\")\n",
    "\n",
    "max_source_length = 512\n",
    "max_target_length = 128\n",
    "\n",
    "task_prefix = \"translate English to German: \"\n",
    "\n",
    "lines = [\n",
    "    \"The house is wonderful\",\n",
    "    \"Welcome to NYC\",\n",
    "    \"HuggingFace is a company\"\n",
    "]\n",
    "\n",
    "input_sequences = [task_prefix + l for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89425685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:8', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:9', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:10', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:11', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:12', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:13', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:14', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:15', device_type='GPU')]\n",
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow GPUS and version:\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eb2dfdb-0ad3-4d0f-81a4-268d92c53759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rishic/anaconda3/envs/spark-dl-tf/lib/python3.11/site-packages/transformers/generation/tf_utils.py:837: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length.  recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727282835.900972 1943970 service.cc:146] XLA service 0x7f33a8044cd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1727282835.901024 1943970 service.cc:154]   StreamExecutor device (0): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727282835.901029 1943970 service.cc:154]   StreamExecutor device (1): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727282835.901039 1943970 service.cc:154]   StreamExecutor device (2): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727282835.901053 1943970 service.cc:154]   StreamExecutor device (3): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727282835.901063 1943970 service.cc:154]   StreamExecutor device (4): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727282835.901077 1943970 service.cc:154]   StreamExecutor device (5): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727282835.901086 1943970 service.cc:154]   StreamExecutor device (6): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727282835.901090 1943970 service.cc:154]   StreamExecutor device (7): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727282835.901099 1943970 service.cc:154]   StreamExecutor device (8): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727282835.901115 1943970 service.cc:154]   StreamExecutor device (9): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727282835.901125 1943970 service.cc:154]   StreamExecutor device (10): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727282835.901128 1943970 service.cc:154]   StreamExecutor device (11): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727282835.901138 1943970 service.cc:154]   StreamExecutor device (12): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727282835.901143 1943970 service.cc:154]   StreamExecutor device (13): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727282835.901153 1943970 service.cc:154]   StreamExecutor device (14): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727282835.901162 1943970 service.cc:154]   StreamExecutor device (15): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-25 16:47:15.905815: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-25 16:47:15.980648: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-09-25 16:47:16.049031: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:762] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.3.107). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "I0000 00:00:1727282836.082512 1943970 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(input_sequences, \n",
    "                      padding=\"longest\", \n",
    "                      max_length=max_source_length,\n",
    "                      return_tensors=\"tf\").input_ids\n",
    "outputs = model.generate(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "720158d4-e0e0-4904-b096-e5aede756afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Das Haus ist wunderbar',\n",
       " 'Willkommen in NYC',\n",
       " 'HuggingFace ist ein Unternehmen']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(o, skip_special_tokens=True) for o in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d4b364b-13cb-48ea-a97a-ccfc9e408075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546eabe0",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f6db1f0-7d68-4af7-8bd6-c9fa45906c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68121304-f1df-466e-9347-c9d2b36a9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6279a849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "24/09/25 16:47:28 WARN Utils: Your hostname, dgx2h0194.spark.sjc4.nvmetal.net resolves to a loopback address: 127.0.1.1; using 10.150.30.2 instead (on interface enp134s0f0np0)\n",
      "24/09/25 16:47:28 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/25 16:47:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "num_threads = 6\n",
    "\n",
    "# Creating a local Spark session for demonstration, in case it hasn't already been created.\n",
    "\n",
    "_config = {\n",
    "    \"spark.master\": f\"local[{num_threads}]\",\n",
    "    \"spark.driver.host\": \"127.0.0.1\",\n",
    "    \"spark.task.maxFailures\": \"1\",\n",
    "    \"spark.driver.memory\": \"8g\",\n",
    "    \"spark.executor.memory\": \"8g\",\n",
    "    \"spark.sql.execution.pyspark.udf.simplifiedTraceback.enabled\": \"false\",\n",
    "    \"spark.sql.pyspark.jvmStacktrace.enabled\": \"true\",\n",
    "    \"spark.sql.execution.arrow.pyspark.enabled\": \"true\",\n",
    "    \"spark.python.worker.reuse\": \"true\",\n",
    "}\n",
    "spark = SparkSession.builder.appName(\"spark-dl-example\")\n",
    "for key, value in _config.items():\n",
    "    spark = spark.config(key, value)\n",
    "spark = spark.getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8453111-d068-49bb-ab91-8ae3d8bcdb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load IMDB reviews (test) dataset\n",
    "data = load_dataset(\"imdb\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ad01d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = []\n",
    "for example in data:\n",
    "    lines.append([example[\"text\"].split(\".\")[0]])\n",
    "\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd5b472-47e8-4804-9907-772793fedb2b",
   "metadata": {},
   "source": [
    "### Create PySpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d24d9404-0269-476e-a9dd-1842667c915a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('lines', StringType(), True)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame(lines, ['lines']).repartition(10)\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4384c762-1f79-4f60-876c-94b1f552e8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(lines=\"i do not understand at all why this movie received such good grades from critics - - i've seen tens of documentaries (on TV) about the wine world which were much much better when (if) you watch it, please think of two very annoying aspects of mondovino : first, the filming is just awful and terrible and upsetting : to me, it looked like the guy behind the camera just received the material and was playing with it : plenty of zooms (for no purpose other than pushing the button in/out) for instance - - i almost stopped to watch it because of that ! secondly, the interviewer (the director i think) is not really relevant : he looks like and ask questions like a boy scout, not like a journalist, even if the general idea and themes would have been interesting, too bad conclusion: overrated documentary, maybe only for guys who do not know nothing about wine => not recommended at all (2/10)\")]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ba3513-82dd-47e7-8193-eb4389458757",
   "metadata": {},
   "source": [
    "### Save the test dataset as parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7eec8ec-4126-4890-b957-025809fad67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.mode(\"overwrite\").parquet(\"imdb_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304e1fc8-42a3-47dd-b3c0-47efd5be1040",
   "metadata": {},
   "source": [
    "### Check arrow memory configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20554ea5-01be-4a30-8607-db5d87786fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"512\")\n",
    "# This line will fail if the vectorized reader runs out of memory\n",
    "assert len(df.head()) > 0, \"`df` should not be empty\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a4ecab-c9d9-466f-ba49-902ad1fd5488",
   "metadata": {},
   "source": [
    "## Inference using Spark DL API (PyTorch)\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7a00479-1347-4de8-8431-faa77f8cdf4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, pandas_udf, struct\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9a0889a-35b4-493a-8197-1146fc7efd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first sentence and add prefix for conditional generation\n",
    "def preprocess(text: pd.Series, prefix: str = \"\") -> pd.Series:\n",
    "    @pandas_udf(\"string\")\n",
    "    def _preprocess(text: pd.Series) -> pd.Series:\n",
    "        return pd.Series([prefix + s.split(\".\")[0] for s in text])\n",
    "    return _preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c483e4d4-9ab1-416f-a766-694e17490fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   lines|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|A ridiculous movie, a terrible editing job, worst screenplay, ridiculous acting, a story that is completely ununderst...|\n",
      "|                                                        Most of this film was okay, for a sequel of a sequel of a sequel|\n",
      "|                                                                                                                 I tried|\n",
      "|                                             This movie attempted to make Stu Ungar's life interesting by being creative|\n",
      "|After I saw this I concluded that it was most likely a chick flick; afterward I found out that Keira's mother wrote t...|\n",
      "|Jeff Speakman never really made it beyond the lowest ranks of martial-artists-turned-actors (lower than Don \"The Drag...|\n",
      "|I haven't seen this movie in years, the last time i did i was really drunk after 5 pints of tenant's at my local With...|\n",
      "|                                                                                Now don't get me wrong I love bad movies|\n",
      "|There I am sitting at home in the morning, suddenly my brother flips on what appears to be the stupidest looking movi...|\n",
      "|Yes, it was an awful movie, but there was a song near the beginning of the movie, I think, called \"I got a Woody\" or ...|\n",
      "|                                                        This was the most uninteresting horror flick I have seen to date|\n",
      "|Another in the long line of Conan wannabes that tired to cash in on that movie's success, this Italian monstrosity is...|\n",
      "|Oh, why did it have to end like this? Laurel and Hardy's last film, from the crudely cranked-up Cuckoo theme (with er...|\n",
      "|Julie Andrews satirically prods her own goody-two-shoes image in this overproduced musical comedy-drama, but if she a...|\n",
      "|                                                                                            'Leatherheads' tries so hard|\n",
      "|                                   If I wouldn't have had any expectations of this film, it might have received a 5 or 6|\n",
      "|With several name actors (Lance Henrikson, David Warner, Joe Don Baker), why was Jeffery Combs given the lead? Henrik...|\n",
      "|                                                                                                   Woa, talk about awful|\n",
      "|                                                                                      The guy mentioned to sue for the 1|\n",
      "|                                                                                           (Warning: Some spoilers ahead|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100)\n",
    "df.show(truncate=120)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "831bc52c-a5c6-4c29-a6da-0566b5167773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df1 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to German: \")).select(\"input\").limit(100).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46dac59c-5a54-4576-91e0-279c8b375b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fef1d846-5852-4762-8527-602f32c0d7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   input|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|Translate English to German: A ridiculous movie, a terrible editing job, worst screenplay, ridiculous acting, a story...|\n",
      "|                           Translate English to German: Most of this film was okay, for a sequel of a sequel of a sequel|\n",
      "|                                                                                    Translate English to German: I tried|\n",
      "|                Translate English to German: This movie attempted to make Stu Ungar's life interesting by being creative|\n",
      "|Translate English to German: After I saw this I concluded that it was most likely a chick flick; afterward I found ou...|\n",
      "|Translate English to German: Jeff Speakman never really made it beyond the lowest ranks of martial-artists-turned-act...|\n",
      "|Translate English to German: I haven't seen this movie in years, the last time i did i was really drunk after 5 pints...|\n",
      "|                                                   Translate English to German: Now don't get me wrong I love bad movies|\n",
      "|Translate English to German: There I am sitting at home in the morning, suddenly my brother flips on what appears to ...|\n",
      "|Translate English to German: Yes, it was an awful movie, but there was a song near the beginning of the movie, I thin...|\n",
      "|                           Translate English to German: This was the most uninteresting horror flick I have seen to date|\n",
      "|Translate English to German: Another in the long line of Conan wannabes that tired to cash in on that movie's success...|\n",
      "|Translate English to German: Oh, why did it have to end like this? Laurel and Hardy's last film, from the crudely cra...|\n",
      "|Translate English to German: Julie Andrews satirically prods her own goody-two-shoes image in this overproduced music...|\n",
      "|                                                               Translate English to German: 'Leatherheads' tries so hard|\n",
      "|      Translate English to German: If I wouldn't have had any expectations of this film, it might have received a 5 or 6|\n",
      "|Translate English to German: With several name actors (Lance Henrikson, David Warner, Joe Don Baker), why was Jeffery...|\n",
      "|                                                                      Translate English to German: Woa, talk about awful|\n",
      "|                                                         Translate English to German: The guy mentioned to sue for the 1|\n",
      "|                                                              Translate English to German: (Warning: Some spoilers ahead|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7ae69d3-70c2-4765-928f-c96a7ba59829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    import numpy as np\n",
    "    from transformers import TFT5ForConditionalGeneration, AutoTokenizer\n",
    "    model = TFT5ForConditionalGeneration.from_pretrained(\"google-t5/t5-small\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-small\")\n",
    "\n",
    "    def predict(inputs):\n",
    "        flattened = np.squeeze(inputs).tolist()   # convert 2d numpy array of string into flattened python list\n",
    "        input_ids = tokenizer(flattened, \n",
    "                              padding=\"longest\", \n",
    "                              max_length=128,\n",
    "                              return_tensors=\"tf\").input_ids\n",
    "        output_ids = model.generate(input_ids)\n",
    "        string_outputs = np.array([tokenizer.decode(o, skip_special_tokens=True) for o in output_ids])\n",
    "        print(\"predict: {}\".format(len(flattened)))\n",
    "        return string_outputs\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36684f59-d947-43f8-a2e8-c7a423764e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = predict_batch_udf(predict_batch_fn,\n",
    "                             return_type=StringType(),\n",
    "                             batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a01c855-8fa1-4765-a3a5-2c9dd872df10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 16:51:16.823248: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-25 16:51:16.846023: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-25 16:51:16.852843: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-25 16:51:16.868781: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-25 16:51:17.936916: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-09-25 16:51:23.206541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 494 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:34:00.0, compute capability: 7.0\n",
      "2024-09-25 16:51:23.220632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30827 MB memory:  -> device: 1, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:36:00.0, compute capability: 7.0\n",
      "2024-09-25 16:51:23.222072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 30827 MB memory:  -> device: 2, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:39:00.0, compute capability: 7.0\n",
      "2024-09-25 16:51:23.223485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 30827 MB memory:  -> device: 3, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2024-09-25 16:51:23.224923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 30827 MB memory:  -> device: 4, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:57:00.0, compute capability: 7.0\n",
      "2024-09-25 16:51:23.226334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 30827 MB memory:  -> device: 5, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:59:00.0, compute capability: 7.0\n",
      "2024-09-25 16:51:23.227753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 30827 MB memory:  -> device: 6, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5c:00.0, compute capability: 7.0\n",
      "2024-09-25 16:51:23.229162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 30827 MB memory:  -> device: 7, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5e:00.0, compute capability: 7.0\n",
      "2024-09-25 16:51:23.230567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:8 with 30827 MB memory:  -> device: 8, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b7:00.0, compute capability: 7.0\n",
      "2024-09-25 16:51:23.231990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:9 with 30827 MB memory:  -> device: 9, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b9:00.0, compute capability: 7.0\n",
      "2024-09-25 16:51:23.233369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:10 with 30827 MB memory:  -> device: 10, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:bc:00.0, compute capability: 7.0\n",
      "2024-09-25 16:51:23.234743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:11 with 30827 MB memory:  -> device: 11, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:be:00.0, compute capability: 7.0\n",
      "2024-09-25 16:51:23.236132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:12 with 30827 MB memory:  -> device: 12, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e0:00.0, compute capability: 7.0\n",
      "2024-09-25 16:51:23.237517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:13 with 30827 MB memory:  -> device: 13, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e2:00.0, compute capability: 7.0\n",
      "2024-09-25 16:51:23.238892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:14 with 30827 MB memory:  -> device: 14, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e5:00.0, compute capability: 7.0\n",
      "2024-09-25 16:51:23.240262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:15 with 30827 MB memory:  -> device: 15, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e7:00.0, compute capability: 7.0\n",
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "/rishic/anaconda3/envs/spark-dl-tf/lib/python3.11/site-packages/transformers/generation/tf_utils.py:837: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length.  recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727283087.372704 1948057 service.cc:146] XLA service 0x7fdd64062b70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1727283087.372747 1948057 service.cc:154]   StreamExecutor device (0): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283087.372765 1948057 service.cc:154]   StreamExecutor device (1): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283087.372768 1948057 service.cc:154]   StreamExecutor device (2): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283087.372772 1948057 service.cc:154]   StreamExecutor device (3): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283087.372776 1948057 service.cc:154]   StreamExecutor device (4): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283087.372785 1948057 service.cc:154]   StreamExecutor device (5): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283087.372800 1948057 service.cc:154]   StreamExecutor device (6): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283087.372803 1948057 service.cc:154]   StreamExecutor device (7): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283087.372812 1948057 service.cc:154]   StreamExecutor device (8): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283087.372823 1948057 service.cc:154]   StreamExecutor device (9): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283087.372839 1948057 service.cc:154]   StreamExecutor device (10): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283087.372854 1948057 service.cc:154]   StreamExecutor device (11): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283087.372862 1948057 service.cc:154]   StreamExecutor device (12): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283087.372873 1948057 service.cc:154]   StreamExecutor device (13): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283087.372888 1948057 service.cc:154]   StreamExecutor device (14): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283087.372897 1948057 service.cc:154]   StreamExecutor device (15): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-25 16:51:27.378010: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-25 16:51:27.437108: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-09-25 16:51:27.467557: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:762] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.3.107). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "I0000 00:00:1727283087.489331 1948057 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.7 ms, sys: 65.8 ms, total: 82.5 ms\n",
      "Wall time: 36.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "preds = df1.withColumn(\"preds\", generate(struct(\"input\")))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d912d4b0-cd0b-44ea-859a-b23455cc2700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10                                                         (0 + 1) / 1]\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.1 ms, sys: 30 ms, total: 49.1 ms\n",
      "Wall time: 23.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df1.withColumn(\"preds\", generate(\"input\"))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fe3d88b-30f7-468f-8db8-1f4118d0f26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10                                                         (0 + 1) / 1]\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.65 ms, sys: 44.4 ms, total: 51 ms\n",
      "Wall time: 23.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df1.withColumn(\"preds\", generate(col(\"input\")))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ad9b365-4b9a-438e-8fdf-47da55cb1cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10                                                         (0 + 1) / 1]\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       input|                                                       preds|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|Translate English to German: A ridiculous movie, a terrib...|Ein lächerlicher Film, eine schreckliche Bearbeitung, sch...|\n",
      "|Translate English to German: Most of this film was okay, ...|Der größte Teil dieses Films war okay, für eine Fortsetzu...|\n",
      "|                        Translate English to German: I tried|                   Ich habe versucht, Englisch zu übersetzen|\n",
      "|Translate English to German: This movie attempted to make...|Dieser Film versuchte, das Leben von Stu Ungar interessan...|\n",
      "|Translate English to German: After I saw this I concluded...|Nach meiner Anzeige kam ich zu dem Schluss, dass es höchs...|\n",
      "|Translate English to German: Jeff Speakman never really m...|Jeff Speakman hat es nie wirklich über die niedrigsten Kl...|\n",
      "|Translate English to German: I haven't seen this movie in...|Ich habe diesen Film nicht in Jahren gesehen, das letzte ...|\n",
      "|Translate English to German: Now don't get me wrong I lov...|  Jetzt mache ich mir nicht recht, ich liebe schlechte Filme|\n",
      "|Translate English to German: There I am sitting at home i...|   Dort sitze ich morgens zu Hause, plötzlich dreht mein Bru|\n",
      "|Translate English to German: Yes, it was an awful movie, ...|              Ja, es war ein schrecklicher Film, aber es gab|\n",
      "|Translate English to German: This was the most uninterest...|Dies war der größte Horrorfilm, den ich bisher gesehen habe.|\n",
      "|Translate English to German: Another in the long line of ...|      Ein weiterer in der langen Linie von Conan-Wünstlingen|\n",
      "|Translate English to German: Oh, why did it have to end l...|        Laurel und Hardy's letzter Film, von dem grotesken C|\n",
      "|Translate English to German: Julie Andrews satirically pr...|  Julie Andrews sah in diesem überproduzierten musikalischen|\n",
      "|   Translate English to German: 'Leatherheads' tries so hard|                                'Leatherheads' tries so hard|\n",
      "|Translate English to German: If I wouldn't have had any e...|Wenn ich keine Erwartungen an diesen Film hätte, hätte er...|\n",
      "|Translate English to German: With several name actors (La...|        Warum hat Jeffery Combs mit mehreren Namenssachen (L|\n",
      "|          Translate English to German: Woa, talk about awful|                         Woa, sprechen Sie über schreckliche|\n",
      "|Translate English to German: The guy mentioned to sue for...|                    Der Name hat es gesagt, daß er für die 1|\n",
      "|  Translate English to German: (Warning: Some spoilers ahead|              (Warning: Einige Vorschläge für die Übersetzer|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 121\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds.show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1eb0c83b-d91b-4f8c-a5e7-c35f55c88108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df2 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to French: \")).select(\"input\").limit(100).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "054f94fd-fe79-41e7-b1c7-6124083acc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   input|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|Translate English to French: A ridiculous movie, a terrible editing job, worst screenplay, ridiculous acting, a story...|\n",
      "|                           Translate English to French: Most of this film was okay, for a sequel of a sequel of a sequel|\n",
      "|                                                                                    Translate English to French: I tried|\n",
      "|                Translate English to French: This movie attempted to make Stu Ungar's life interesting by being creative|\n",
      "|Translate English to French: After I saw this I concluded that it was most likely a chick flick; afterward I found ou...|\n",
      "|Translate English to French: Jeff Speakman never really made it beyond the lowest ranks of martial-artists-turned-act...|\n",
      "|Translate English to French: I haven't seen this movie in years, the last time i did i was really drunk after 5 pints...|\n",
      "|                                                   Translate English to French: Now don't get me wrong I love bad movies|\n",
      "|Translate English to French: There I am sitting at home in the morning, suddenly my brother flips on what appears to ...|\n",
      "|Translate English to French: Yes, it was an awful movie, but there was a song near the beginning of the movie, I thin...|\n",
      "|                           Translate English to French: This was the most uninteresting horror flick I have seen to date|\n",
      "|Translate English to French: Another in the long line of Conan wannabes that tired to cash in on that movie's success...|\n",
      "|Translate English to French: Oh, why did it have to end like this? Laurel and Hardy's last film, from the crudely cra...|\n",
      "|Translate English to French: Julie Andrews satirically prods her own goody-two-shoes image in this overproduced music...|\n",
      "|                                                               Translate English to French: 'Leatherheads' tries so hard|\n",
      "|      Translate English to French: If I wouldn't have had any expectations of this film, it might have received a 5 or 6|\n",
      "|Translate English to French: With several name actors (Lance Henrikson, David Warner, Joe Don Baker), why was Jeffery...|\n",
      "|                                                                      Translate English to French: Woa, talk about awful|\n",
      "|                                                         Translate English to French: The guy mentioned to sue for the 1|\n",
      "|                                                              Translate English to French: (Warning: Some spoilers ahead|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df2.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f6b70f9-188a-402b-9143-78a5788140e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 16:52:59.690590: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-25 16:52:59.713218: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-25 16:52:59.720094: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-25 16:52:59.736597: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-25 16:53:00.743473: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-09-25 16:53:06.205151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 494 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:34:00.0, compute capability: 7.0\n",
      "2024-09-25 16:53:06.224883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30827 MB memory:  -> device: 1, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:36:00.0, compute capability: 7.0\n",
      "2024-09-25 16:53:06.241005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 30827 MB memory:  -> device: 2, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:39:00.0, compute capability: 7.0\n",
      "2024-09-25 16:53:06.256822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 30827 MB memory:  -> device: 3, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2024-09-25 16:53:06.267767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 30827 MB memory:  -> device: 4, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:57:00.0, compute capability: 7.0\n",
      "2024-09-25 16:53:06.269093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 30827 MB memory:  -> device: 5, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:59:00.0, compute capability: 7.0\n",
      "2024-09-25 16:53:06.270278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 30827 MB memory:  -> device: 6, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5c:00.0, compute capability: 7.0\n",
      "2024-09-25 16:53:06.271616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 30827 MB memory:  -> device: 7, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5e:00.0, compute capability: 7.0\n",
      "2024-09-25 16:53:06.283517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:8 with 30827 MB memory:  -> device: 8, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b7:00.0, compute capability: 7.0\n",
      "2024-09-25 16:53:06.296795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:9 with 30827 MB memory:  -> device: 9, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b9:00.0, compute capability: 7.0\n",
      "2024-09-25 16:53:06.320351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:10 with 30827 MB memory:  -> device: 10, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:bc:00.0, compute capability: 7.0\n",
      "2024-09-25 16:53:06.321673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:11 with 30827 MB memory:  -> device: 11, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:be:00.0, compute capability: 7.0\n",
      "2024-09-25 16:53:06.330041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:12 with 30827 MB memory:  -> device: 12, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e0:00.0, compute capability: 7.0\n",
      "2024-09-25 16:53:06.331335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:13 with 30827 MB memory:  -> device: 13, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e2:00.0, compute capability: 7.0\n",
      "2024-09-25 16:53:06.332619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:14 with 30827 MB memory:  -> device: 14, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e5:00.0, compute capability: 7.0\n",
      "2024-09-25 16:53:06.333934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:15 with 30827 MB memory:  -> device: 15, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e7:00.0, compute capability: 7.0\n",
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "/rishic/anaconda3/envs/spark-dl-tf/lib/python3.11/site-packages/transformers/generation/tf_utils.py:837: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length.  recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727283190.300475 1951155 service.cc:146] XLA service 0x7fd974044870 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1727283190.300508 1951155 service.cc:154]   StreamExecutor device (0): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283190.300516 1951155 service.cc:154]   StreamExecutor device (1): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283190.300520 1951155 service.cc:154]   StreamExecutor device (2): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283190.300523 1951155 service.cc:154]   StreamExecutor device (3): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283190.300527 1951155 service.cc:154]   StreamExecutor device (4): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283190.300531 1951155 service.cc:154]   StreamExecutor device (5): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283190.300537 1951155 service.cc:154]   StreamExecutor device (6): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283190.300540 1951155 service.cc:154]   StreamExecutor device (7): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283190.300544 1951155 service.cc:154]   StreamExecutor device (8): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283190.300548 1951155 service.cc:154]   StreamExecutor device (9): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283190.300554 1951155 service.cc:154]   StreamExecutor device (10): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283190.300559 1951155 service.cc:154]   StreamExecutor device (11): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283190.300564 1951155 service.cc:154]   StreamExecutor device (12): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283190.300570 1951155 service.cc:154]   StreamExecutor device (13): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283190.300576 1951155 service.cc:154]   StreamExecutor device (14): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727283190.300580 1951155 service.cc:154]   StreamExecutor device (15): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-25 16:53:10.305230: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-25 16:53:10.349489: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-09-25 16:53:10.399361: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:762] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.3.107). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "I0000 00:00:1727283190.420446 1951155 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.1 ms, sys: 43 ms, total: 92.1 ms\n",
      "Wall time: 36.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "preds = df2.withColumn(\"preds\", generate(struct(\"input\")))\n",
    "result = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "031a6a5e-7999-4653-b394-19ed478d8c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10                                                         (0 + 1) / 1]\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.41 ms, sys: 46 ms, total: 53.4 ms\n",
      "Wall time: 23.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df2.withColumn(\"preds\", generate(\"input\"))\n",
    "result = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "229b6515-82f6-4e9c-90f0-a9c3cfb26301",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10                                                         (0 + 1) / 1]\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.6 ms, sys: 37.6 ms, total: 55.2 ms\n",
      "Wall time: 22.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df2.withColumn(\"preds\", generate(col(\"input\")))\n",
    "result = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8be750ac-fa39-452e-bb4c-c2270bc2f70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10                                                         (0 + 1) / 1]\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       input|                                                       preds|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|Translate English to French: A ridiculous movie, a terrib...|Un film ridicule, un terrible travail de rédaction, le pi...|\n",
      "|Translate English to French: Most of this film was okay, ...|La plupart de ce film était en bonne et due forme, pour u...|\n",
      "|                        Translate English to French: I tried|                                                 J'ai essayé|\n",
      "|Translate English to French: This movie attempted to make...|Ce film tentait de rendre la vie de Stu Ungar intéressant...|\n",
      "|Translate English to French: After I saw this I concluded...|Après avoir vu ce film, j'ai conclu qu'il était très prob...|\n",
      "|Translate English to French: Jeff Speakman never really m...|Jeff Speakman n'a jamais vraiment franchi les rangs les p...|\n",
      "|Translate English to French: I haven't seen this movie in...|Je n'ai pas vu ce film depuis des années, la dernière foi...|\n",
      "|Translate English to French: Now don't get me wrong I lov...|     Maintenant, ne pas me grecher Je aime les mauvais films|\n",
      "|Translate English to French: There I am sitting at home i...|       l'intérieur, je me trouve à la maison le matin, sous-|\n",
      "|Translate English to French: Yes, it was an awful movie, ...|  Oui, c'était un film terrible, mais il y avait une chanson|\n",
      "|Translate English to French: This was the most uninterest...|         Ce fut le plus inquiétant et le plus inquiétant d'h|\n",
      "|Translate English to French: Another in the long line of ...|  Une autre en longue ligne de conan qui a eu la fatigue de |\n",
      "|Translate English to French: Oh, why did it have to end l...|            Laurel et Hardy s'en sont rendus dans le dernier|\n",
      "|Translate English to French: Julie Andrews satirically pr...|Julie Andrews s'enrôle satiriquement dans cette comédie m...|\n",
      "|   Translate English to French: 'Leatherheads' tries so hard|                                'Leatherheads' essaie si dur|\n",
      "|Translate English to French: If I wouldn't have had any e...|                       Si je n'aurais pas eu d'attentes à ce|\n",
      "|Translate English to French: With several name actors (La...|Avec plusieurs acteurs de nom (Lance Henrikson, David War...|\n",
      "|          Translate English to French: Woa, talk about awful|                                                            |\n",
      "|Translate English to French: The guy mentioned to sue for...|Le châssis mentionné pour intenter une action en justice ...|\n",
      "|  Translate English to French: (Warning: Some spoilers ahead|               (Avertissement : Quelques spoilers à l'avenir|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 121\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds.show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcabb2a8-3880-46ec-8e01-5a10f71fe83d",
   "metadata": {},
   "source": [
    "### Using Triton Inference Server\n",
    "\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d98fa52-7665-49bf-865a-feec86effe23",
   "metadata": {},
   "source": [
    "This notebook uses the [Python backend with a custom execution environment](https://github.com/triton-inference-server/python_backend#creating-custom-execution-environments) with the compatible versions of Python/Numpy for Triton 24.08, using a conda-pack environment created as follows:\n",
    "```\n",
    "conda create -n huggingface -c conda-forge python=3.10.0\n",
    "conda activate huggingface\n",
    "\n",
    "export PYTHONNOUSERSITE=True\n",
    "pip install numpy<2 conda-pack sentencepiece sentence_transformers transformers\n",
    "\n",
    "conda-pack  # huggingface.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b858cf85-82e6-41ef-905b-d8c5d6fea492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05ce7c77-d562-45e8-89bb-cd656aba5a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# copy custom model to expected layout for Triton\n",
    "rm -rf models\n",
    "mkdir -p models\n",
    "cp -r models_config/hf_generation models\n",
    "\n",
    "# add custom execution environment\n",
    "cp huggingface.tar.gz models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a552865c-5dad-4f25-8834-f41e253ac2f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afd00b7e-8150-4c95-a2e4-037e9c90f92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> starting triton: dc09082cc87e                                  (0 + 1) / 1]\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_executors = 1\n",
    "triton_models_dir = \"{}/models\".format(os.getcwd())\n",
    "huggingface_cache_dir = \"{}/.cache/huggingface\".format(os.path.expanduser('~'))\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:24.08-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            environment=[\n",
    "                \"TRANSFORMERS_CACHE=/cache\"\n",
    "            ],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"1G\",\n",
    "            volumes={\n",
    "                triton_models_dir: {\"bind\": \"/models\", \"mode\": \"ro\"},\n",
    "                huggingface_cache_dir: {\"bind\": \"/cache\", \"mode\": \"rw\"}\n",
    "            }\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        ready = False\n",
    "        while not ready:\n",
    "            try:\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                time.sleep(5)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528d2df6-49fc-4be7-a534-a087dfe31c84",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a997c33-5202-466d-8304-b8c30f32978f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import partial\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, pandas_udf, struct\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9dea1875-6b95-4fc0-926d-a625a441b33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d6c54e7-534d-406f-b8e6-fd592efd0ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first sentence and add prefix for conditional generation\n",
    "def preprocess(text: pd.Series, prefix: str = \"\") -> pd.Series:\n",
    "    @pandas_udf(\"string\")\n",
    "    def _preprocess(text: pd.Series) -> pd.Series:\n",
    "        return pd.Series([prefix + s.split(\".\")[0] for s in text])\n",
    "    return _preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc1bbbe3-4232-49e5-80f6-99976524b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df1 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to German: \")).select(\"input\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5d10c61c-6102-4d19-8dd6-0c7b5b65343e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   input|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|Translate English to German: A ridiculous movie, a terrible editing job, worst screenplay, ridiculous acting, a story...|\n",
      "|                           Translate English to German: Most of this film was okay, for a sequel of a sequel of a sequel|\n",
      "|                                                                                    Translate English to German: I tried|\n",
      "|                Translate English to German: This movie attempted to make Stu Ungar's life interesting by being creative|\n",
      "|Translate English to German: After I saw this I concluded that it was most likely a chick flick; afterward I found ou...|\n",
      "|Translate English to German: Jeff Speakman never really made it beyond the lowest ranks of martial-artists-turned-act...|\n",
      "|Translate English to German: I haven't seen this movie in years, the last time i did i was really drunk after 5 pints...|\n",
      "|                                                   Translate English to German: Now don't get me wrong I love bad movies|\n",
      "|Translate English to German: There I am sitting at home in the morning, suddenly my brother flips on what appears to ...|\n",
      "|Translate English to German: Yes, it was an awful movie, but there was a song near the beginning of the movie, I thin...|\n",
      "|                           Translate English to German: This was the most uninteresting horror flick I have seen to date|\n",
      "|Translate English to German: Another in the long line of Conan wannabes that tired to cash in on that movie's success...|\n",
      "|Translate English to German: Oh, why did it have to end like this? Laurel and Hardy's last film, from the crudely cra...|\n",
      "|Translate English to German: Julie Andrews satirically prods her own goody-two-shoes image in this overproduced music...|\n",
      "|                                                               Translate English to German: 'Leatherheads' tries so hard|\n",
      "|      Translate English to German: If I wouldn't have had any expectations of this film, it might have received a 5 or 6|\n",
      "|Translate English to German: With several name actors (Lance Henrikson, David Warner, Joe Don Baker), why was Jeffery...|\n",
      "|                                                                      Translate English to German: Woa, talk about awful|\n",
      "|                                                         Translate English to German: The guy mentioned to sue for the 1|\n",
      "|                                                              Translate English to German: (Warning: Some spoilers ahead|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e0907da-a5d9-4c3b-9db4-ce5e70ca9bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool8),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name()].astype(np_types[i.datatype()]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        \n",
    "        if len(model_meta.outputs) > 1:\n",
    "            # return dictionary of numpy arrays\n",
    "            return {o.name: response.as_numpy(o.name) for o in model_meta.outputs}\n",
    "        else:\n",
    "            # return single numpy array\n",
    "            return response.as_numpy(model_meta.outputs[0].name)\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9308bdd7-6f67-484d-8b51-dd1e1b2960ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = predict_batch_udf(partial(triton_fn, triton_uri=\"localhost:8001\", model_name=\"hf_generation\"),\n",
    "                             return_type=StringType(),\n",
    "                             input_tensor_shapes=[[1]],\n",
    "                             batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38484ffd-370d-492b-8ca4-9eff9f242a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1943561/3110230631.py:6: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.1 ms, sys: 23.2 ms, total: 61.3 ms\n",
      "Wall time: 10.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "preds = df1.withColumn(\"preds\", generate(struct(\"input\")))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ebcb6699-3ac2-4529-ab0f-fab0a5e792da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.8 ms, sys: 24.8 ms, total: 45.7 ms\n",
      "Wall time: 7.33 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df1.withColumn(\"preds\", generate(\"input\"))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e2ed18ad-d00b-472c-b2c3-047932f2105d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 59:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.7 ms, sys: 16.1 ms, total: 39.8 ms\n",
      "Wall time: 5.59 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df1.withColumn(\"preds\", generate(col(\"input\")))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0cd64a1c-beb8-47d5-ac6f-e8525bb61176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 61:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       input|                                                       preds|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|Translate English to German: A ridiculous movie, a terrib...|Ein lächerlicher Film, eine schreckliche Bearbeitung, sch...|\n",
      "|Translate English to German: Most of this film was okay, ...|Der größte Teil dieses Films war okay, für eine Fortsetzu...|\n",
      "|                        Translate English to German: I tried|                   Ich habe versucht, Englisch zu übersetzen|\n",
      "|Translate English to German: This movie attempted to make...|Dieser Film versuchte, das Leben von Stu Ungar interessan...|\n",
      "|Translate English to German: After I saw this I concluded...|Nach meiner Anzeige kam ich zu dem Schluss, dass es höchs...|\n",
      "|Translate English to German: Jeff Speakman never really m...|Jeff Speakman hat es nie wirklich über die niedrigsten Kl...|\n",
      "|Translate English to German: I haven't seen this movie in...|Ich habe diesen Film nicht in Jahren gesehen, das letzte ...|\n",
      "|Translate English to German: Now don't get me wrong I lov...|  Jetzt mache ich mir nicht recht, ich liebe schlechte Filme|\n",
      "|Translate English to German: There I am sitting at home i...|   Dort sitze ich morgens zu Hause, plötzlich dreht mein Bru|\n",
      "|Translate English to German: Yes, it was an awful movie, ...|              Ja, es war ein schrecklicher Film, aber es gab|\n",
      "|Translate English to German: This was the most uninterest...|Dies war der größte Horrorfilm, den ich bisher gesehen habe.|\n",
      "|Translate English to German: Another in the long line of ...|      Ein weiterer in der langen Linie von Conan-Wünstlingen|\n",
      "|Translate English to German: Oh, why did it have to end l...|        Laurel und Hardy's letzter Film, von dem grotesken C|\n",
      "|Translate English to German: Julie Andrews satirically pr...|  Julie Andrews sah in diesem überproduzierten musikalischen|\n",
      "|   Translate English to German: 'Leatherheads' tries so hard|                                'Leatherheads' tries so hard|\n",
      "|Translate English to German: If I wouldn't have had any e...|Wenn ich keine Erwartungen an diesen Film hätte, hätte er...|\n",
      "|Translate English to German: With several name actors (La...|        Warum hat Jeffery Combs mit mehreren Namenssachen (L|\n",
      "|          Translate English to German: Woa, talk about awful|                         Woa, sprechen Sie über schreckliche|\n",
      "|Translate English to German: The guy mentioned to sue for...|                    Der Name hat es gesagt, daß er für die 1|\n",
      "|  Translate English to German: (Warning: Some spoilers ahead|              (Warning: Einige Vorschläge für die Übersetzer|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds.show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af70fed8-0f2b-4ea7-841c-476afdf9b1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/25 16:55:58 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df2 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to French: \")).select(\"input\").limit(100).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ef075e10-e22c-4236-9e0b-cb47cf2d3d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   input|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|Translate English to French: A ridiculous movie, a terrible editing job, worst screenplay, ridiculous acting, a story...|\n",
      "|                           Translate English to French: Most of this film was okay, for a sequel of a sequel of a sequel|\n",
      "|                                                                                    Translate English to French: I tried|\n",
      "|                Translate English to French: This movie attempted to make Stu Ungar's life interesting by being creative|\n",
      "|Translate English to French: After I saw this I concluded that it was most likely a chick flick; afterward I found ou...|\n",
      "|Translate English to French: Jeff Speakman never really made it beyond the lowest ranks of martial-artists-turned-act...|\n",
      "|Translate English to French: I haven't seen this movie in years, the last time i did i was really drunk after 5 pints...|\n",
      "|                                                   Translate English to French: Now don't get me wrong I love bad movies|\n",
      "|Translate English to French: There I am sitting at home in the morning, suddenly my brother flips on what appears to ...|\n",
      "|Translate English to French: Yes, it was an awful movie, but there was a song near the beginning of the movie, I thin...|\n",
      "|                           Translate English to French: This was the most uninteresting horror flick I have seen to date|\n",
      "|Translate English to French: Another in the long line of Conan wannabes that tired to cash in on that movie's success...|\n",
      "|Translate English to French: Oh, why did it have to end like this? Laurel and Hardy's last film, from the crudely cra...|\n",
      "|Translate English to French: Julie Andrews satirically prods her own goody-two-shoes image in this overproduced music...|\n",
      "|                                                               Translate English to French: 'Leatherheads' tries so hard|\n",
      "|      Translate English to French: If I wouldn't have had any expectations of this film, it might have received a 5 or 6|\n",
      "|Translate English to French: With several name actors (Lance Henrikson, David Warner, Joe Don Baker), why was Jeffery...|\n",
      "|                                                                      Translate English to French: Woa, talk about awful|\n",
      "|                                                         Translate English to French: The guy mentioned to sue for the 1|\n",
      "|                                                              Translate English to French: (Warning: Some spoilers ahead|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2e7e4af8-b815-4375-b851-8368309ee8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1943561/3110230631.py:6: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.4 ms, sys: 10.7 ms, total: 36.1 ms\n",
      "Wall time: 5.89 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df2.withColumn(\"preds\", generate(struct(\"input\")))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7b0aefb0-a96b-4791-a23c-1ce9b24eb20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 67:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.7 ms, sys: 16.7 ms, total: 33.4 ms\n",
      "Wall time: 6.86 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df2.withColumn(\"preds\", generate(\"input\"))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1214b75b-a373-4579-b4c6-0cb8627da776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 69:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.05 ms, sys: 28.8 ms, total: 32.9 ms\n",
      "Wall time: 6.06 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df2.withColumn(\"preds\", generate(col(\"input\")))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c9dbd21f-9e37-4221-b765-80ba8c80b884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 71:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       input|                                                       preds|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|Translate English to French: A ridiculous movie, a terrib...|Un film ridicule, un terrible travail de rédaction, le pi...|\n",
      "|Translate English to French: Most of this film was okay, ...|La plupart de ce film était en bonne et due forme, pour u...|\n",
      "|                        Translate English to French: I tried|                                                 J'ai essayé|\n",
      "|Translate English to French: This movie attempted to make...|Ce film tentait de rendre la vie de Stu Ungar intéressant...|\n",
      "|Translate English to French: After I saw this I concluded...|Après avoir vu ce film, j'ai conclu qu'il était très prob...|\n",
      "|Translate English to French: Jeff Speakman never really m...|Jeff Speakman n'a jamais vraiment franchi les rangs les p...|\n",
      "|Translate English to French: I haven't seen this movie in...|Je n'ai pas vu ce film depuis des années, la dernière foi...|\n",
      "|Translate English to French: Now don't get me wrong I lov...|     Maintenant, ne pas me grecher Je aime les mauvais films|\n",
      "|Translate English to French: There I am sitting at home i...|       l'intérieur, je me trouve à la maison le matin, sous-|\n",
      "|Translate English to French: Yes, it was an awful movie, ...|  Oui, c'était un film terrible, mais il y avait une chanson|\n",
      "|Translate English to French: This was the most uninterest...|         Ce fut le plus inquiétant et le plus inquiétant d'h|\n",
      "|Translate English to French: Another in the long line of ...|   Une autre en longue ligne de conan qui a eu la fatigue de|\n",
      "|Translate English to French: Oh, why did it have to end l...|            Laurel et Hardy s'en sont rendus dans le dernier|\n",
      "|Translate English to French: Julie Andrews satirically pr...|Julie Andrews s'enrôle satiriquement dans cette comédie m...|\n",
      "|   Translate English to French: 'Leatherheads' tries so hard|                                'Leatherheads' essaie si dur|\n",
      "|Translate English to French: If I wouldn't have had any e...|                       Si je n'aurais pas eu d'attentes à ce|\n",
      "|Translate English to French: With several name actors (La...|Avec plusieurs acteurs de nom (Lance Henrikson, David War...|\n",
      "|          Translate English to French: Woa, talk about awful|                                                            |\n",
      "|Translate English to French: The guy mentioned to sue for...|Le châssis mentionné pour intenter une action en justice ...|\n",
      "|  Translate English to French: (Warning: Some spoilers ahead|               (Avertissement : Quelques spoilers à l'avenir|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds.show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919e3113-64dd-482a-9233-6607b3f63c1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "425d3b28-7705-45ba-8a18-ad34fc895219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> stopping containers: ['dc09082cc87e']\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2dec80ca-7a7c-46a9-97c0-7afb1572f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43118ab-fc0a-4f64-a126-4302e615654a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
