{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "777fc40d",
   "metadata": {},
   "source": [
    "# PySpark Huggingface Inferencing\n",
    "## Conditional generation\n",
    "\n",
    "From: https://huggingface.co/docs/transformers/model_doc/t5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcbccb1-3f82-425b-a82d-12d4f2f91d6e",
   "metadata": {},
   "source": [
    "### Using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "731faab7-a700-46f8-bba5-1c8764e5eacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rishic/anaconda3/envs/spark-rapids-examples/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google-t5/t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google-t5/t5-small\")\n",
    "\n",
    "max_source_length = 512\n",
    "max_target_length = 128\n",
    "\n",
    "task_prefix = \"translate English to German: \"\n",
    "\n",
    "lines = [\n",
    "    \"The house is wonderful\",\n",
    "    \"Welcome to NYC\",\n",
    "    \"HuggingFace is a company\"\n",
    "]\n",
    "\n",
    "input_sequences = [task_prefix + l for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45abfa26-02da-4d4a-a925-85b387de0ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rishic/anaconda3/envs/spark-rapids-examples/lib/python3.11/site-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(input_sequences, \n",
    "                      padding=\"longest\", \n",
    "                      max_length=max_source_length,\n",
    "                      truncation=True,\n",
    "                      return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = model.generate(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72972ade-3a97-4bb3-9efa-31039a1a9442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Das Haus ist wunderbar',\n",
       " 'Willkommen in NYC',\n",
       " 'HuggingFace ist ein Unternehmen']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(o, skip_special_tokens=True) for o in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18d060a1-19ef-4101-a9a6-2fdc184e07b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c79ac4-bf25-421e-b55e-020d6d9e15d5",
   "metadata": {},
   "source": [
    "### Using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f0dbf3-712b-4c58-85eb-261ce15bb2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 18:04:10.354829: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-18 18:04:10.354873: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-18 18:04:10.356281: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-18 18:04:10.363572: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-18 18:04:11.216255: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFT5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2684fb41-9467-40c0-9d7e-a1cc867c5a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 18:04:17.110820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30765 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:34:00.0, compute capability: 7.0\n",
      "2024-09-18 18:04:17.112209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 31135 MB memory:  -> device: 1, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:36:00.0, compute capability: 7.0\n",
      "2024-09-18 18:04:17.113375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 31135 MB memory:  -> device: 2, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:39:00.0, compute capability: 7.0\n",
      "2024-09-18 18:04:17.114536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 31135 MB memory:  -> device: 3, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2024-09-18 18:04:17.115721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 31135 MB memory:  -> device: 4, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:57:00.0, compute capability: 7.0\n",
      "2024-09-18 18:04:17.117117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 31135 MB memory:  -> device: 5, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:59:00.0, compute capability: 7.0\n",
      "2024-09-18 18:04:17.118264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 31135 MB memory:  -> device: 6, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5c:00.0, compute capability: 7.0\n",
      "2024-09-18 18:04:17.119415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 31135 MB memory:  -> device: 7, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5e:00.0, compute capability: 7.0\n",
      "2024-09-18 18:04:17.120597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:8 with 31135 MB memory:  -> device: 8, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b7:00.0, compute capability: 7.0\n",
      "2024-09-18 18:04:17.121749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:9 with 31135 MB memory:  -> device: 9, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b9:00.0, compute capability: 7.0\n",
      "2024-09-18 18:04:17.122919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:10 with 31135 MB memory:  -> device: 10, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:bc:00.0, compute capability: 7.0\n",
      "2024-09-18 18:04:17.124107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:11 with 31135 MB memory:  -> device: 11, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:be:00.0, compute capability: 7.0\n",
      "2024-09-18 18:04:17.125295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:12 with 31135 MB memory:  -> device: 12, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e0:00.0, compute capability: 7.0\n",
      "2024-09-18 18:04:17.126428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:13 with 31135 MB memory:  -> device: 13, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e2:00.0, compute capability: 7.0\n",
      "2024-09-18 18:04:17.127566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:14 with 31135 MB memory:  -> device: 14, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e5:00.0, compute capability: 7.0\n",
      "2024-09-18 18:04:17.128732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:15 with 31135 MB memory:  -> device: 15, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e7:00.0, compute capability: 7.0\n",
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-small\")\n",
    "model = TFT5ForConditionalGeneration.from_pretrained(\"google-t5/t5-small\")\n",
    "\n",
    "max_source_length = 512\n",
    "max_target_length = 128\n",
    "\n",
    "task_prefix = \"translate English to German: \"\n",
    "\n",
    "lines = [\n",
    "    \"The house is wonderful\",\n",
    "    \"Welcome to NYC\",\n",
    "    \"HuggingFace is a company\"\n",
    "]\n",
    "\n",
    "input_sequences = [task_prefix + l for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89425685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:8', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:9', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:10', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:11', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:12', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:13', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:14', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:15', device_type='GPU')]\n",
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow GPUS and version:\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eb2dfdb-0ad3-4d0f-81a4-268d92c53759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rishic/anaconda3/envs/spark-rapids-examples/lib/python3.11/site-packages/transformers/generation/tf_utils.py:837: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length.  recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "2024-09-18 18:04:20.353882: I external/local_xla/xla/service/service.cc:168] XLA service 0x280e86d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-09-18 18:04:20.353910: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-18 18:04:20.353917: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-18 18:04:20.353925: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (2): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-18 18:04:20.353931: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (3): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-18 18:04:20.353938: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (4): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-18 18:04:20.353944: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (5): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-18 18:04:20.353951: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (6): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-18 18:04:20.353958: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (7): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-18 18:04:20.353965: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (8): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-18 18:04:20.353972: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (9): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-18 18:04:20.353978: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (10): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-18 18:04:20.353985: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (11): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-18 18:04:20.353992: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (12): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-18 18:04:20.353997: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (13): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-18 18:04:20.354004: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (14): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-18 18:04:20.354011: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (15): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-18 18:04:20.357461: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-18 18:04:20.414556: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726682660.470765 2125519 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "#os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_cuda_data_dir=/usr/lib/cuda\" # set to location of cuda/nvvm/libdevice\n",
    "\n",
    "input_ids = tokenizer(input_sequences, \n",
    "                      padding=\"longest\", \n",
    "                      max_length=max_source_length,\n",
    "                      return_tensors=\"tf\").input_ids\n",
    "outputs = model.generate(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "720158d4-e0e0-4904-b096-e5aede756afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Das Haus ist wunderbar',\n",
       " 'Willkommen in NYC',\n",
       " 'HuggingFace ist ein Unternehmen']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(o, skip_special_tokens=True) for o in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d4b364b-13cb-48ea-a97a-ccfc9e408075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546eabe0",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f6db1f0-7d68-4af7-8bd6-c9fa45906c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68121304-f1df-466e-9347-c9d2b36a9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6279a849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "24/09/18 18:04:26 WARN Utils: Your hostname, dgx2h0194.spark.sjc4.nvmetal.net resolves to a loopback address: 127.0.1.1; using 10.150.30.2 instead (on interface enp134s0f0np0)\n",
      "24/09/18 18:04:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/18 18:04:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "num_threads = 6\n",
    "\n",
    "# Creating a local Spark session for demonstration, in case it hasn't already been created.\n",
    "\n",
    "_config = {\n",
    "    \"spark.master\": f\"local[{num_threads}]\",\n",
    "    \"spark.driver.host\": \"127.0.0.1\",\n",
    "    \"spark.task.maxFailures\": \"1\",\n",
    "    \"spark.driver.memory\": \"8g\",\n",
    "    \"spark.executor.memory\": \"8g\",\n",
    "    \"spark.sql.execution.pyspark.udf.simplifiedTraceback.enabled\": \"false\",\n",
    "    \"spark.sql.pyspark.jvmStacktrace.enabled\": \"true\",\n",
    "    \"spark.sql.execution.arrow.pyspark.enabled\": \"true\",\n",
    "    \"spark.python.worker.reuse\": \"true\",\n",
    "}\n",
    "spark = SparkSession.builder.appName(\"spark-dl-example\")\n",
    "for key, value in _config.items():\n",
    "    spark = spark.config(key, value)\n",
    "spark = spark.getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8453111-d068-49bb-ab91-8ae3d8bcdb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load IMDB reviews (test) dataset\n",
    "data = load_dataset(\"imdb\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ad01d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = []\n",
    "for example in data:\n",
    "    lines.append([example[\"text\"].split(\".\")[0]])\n",
    "\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd5b472-47e8-4804-9907-772793fedb2b",
   "metadata": {},
   "source": [
    "### Create PySpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d24d9404-0269-476e-a9dd-1842667c915a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('lines', StringType(), True)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame(lines, ['lines']).repartition(10)\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4384c762-1f79-4f60-876c-94b1f552e8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/18 18:04:30 WARN TaskSetManager: Stage 0 contains a task of very large size (5123 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(lines='EVAN ALMIGHTY (2007) ** Steve Carell, Morgan Freeman, Lauren Graham, Johnny Simmons, Graham Phillips, Jimmy Bennett, John Goodman, Wanda Sykes, John Michael Higgins, Jonah Hill, Molly Shannon, Ed Helms, (Cameo: Jon Stewart as himself) Strained \\'sequel\\' to \"BRUCE ALMIGHTY\" with Carell\\'s jerk anchorman Evan Baxter leaving TV to begin his stint as a freshman Congressional rep has his hands full when God (Freeman reprising his holy role; Jim Carrey wisely avoided the \\'calling\\') demands he build an ark like Noah and the hilarity ensues (or should have). The Godforsaken sitcom-y script by Steve Oedekerk, Joel Cohen & Alec Sokolow is absolutely lame and only Carell\\'s amiable persona transcends his vain Evan into something resembling a human being. The end result is a lot of bird poop gags and overall bloat (reportedly costing $175 M for the CGI F/X). Sykes steals the show as Evan\\'s sarcastic assistant. Sacrilegiously unfunny. (Dir: Tom Shadyac)')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ba3513-82dd-47e7-8193-eb4389458757",
   "metadata": {},
   "source": [
    "### Save the test dataset as parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7eec8ec-4126-4890-b957-025809fad67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/18 18:04:32 WARN TaskSetManager: Stage 3 contains a task of very large size (5123 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.mode(\"overwrite\").parquet(\"imdb_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304e1fc8-42a3-47dd-b3c0-47efd5be1040",
   "metadata": {},
   "source": [
    "### Check arrow memory configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20554ea5-01be-4a30-8607-db5d87786fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/18 18:04:33 WARN TaskSetManager: Stage 6 contains a task of very large size (5123 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"512\")\n",
    "# This line will fail if the vectorized reader runs out of memory\n",
    "assert len(df.head()) > 0, \"`df` should not be empty\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a4ecab-c9d9-466f-ba49-902ad1fd5488",
   "metadata": {},
   "source": [
    "## Inference using Spark DL API (PyTorch)\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7a00479-1347-4de8-8431-faa77f8cdf4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, pandas_udf, struct\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9a0889a-35b4-493a-8197-1146fc7efd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first sentence and add prefix for conditional generation\n",
    "def preprocess(text: pd.Series, prefix: str = \"\") -> pd.Series:\n",
    "    @pandas_udf(\"string\")\n",
    "    def _preprocess(text: pd.Series) -> pd.Series:\n",
    "        return pd.Series([prefix + s.split(\".\")[0] for s in text])\n",
    "    return _preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c483e4d4-9ab1-416f-a766-694e17490fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   lines|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|In following Dylan Moran's star from the charming misanthrope bookstore owner in the surrealist sitcom Black Books, I...|\n",
      "|Here in Australia Nights in Rodanthe is being promoted in the same class as the Notebook. Quite frankly what a lot of...|\n",
      "|The Tender Hook, or, Who Killed The Australian Film Industry? Case No. 278. This sorry excuse for a period drama take...|\n",
      "|The only reason I'm even giving this movie a 4 is because it was made in to an episode of Mystery Science Theater 300...|\n",
      "|Hooray for Title Misspellings! After reading reviews and contemplating, my girlfriend and I confirmed that this movie...|\n",
      "|This movie makes you wish imdb would let you vote a zero. One of the two movies I've ever walked out of. It's very ha...|\n",
      "|To me this film is just a very very lame teen party movie with all the normal clichés and boring stereotyped characte...|\n",
      "|I tried. God knows I tried to like this Swiss Cheese of a movie, but the story was too full of holes, some big enough...|\n",
      "|Awkward disaster mishmash has a team of scavengers coming across the overturned S.S. Poseidon, hoping to loot it befo...|\n",
      "|According to the blurb on the back of the DVD case; Jonothan Ross 'laughed until a little bit of wee came out'. I sus...|\n",
      "|It'll be a blue Christmas indeed if you subject you're family to this. I loved the original movie, and this one was n...|\n",
      "|This is the story of a maniac cop who, for some reason, has it in for a young college stud and his mates. After they ...|\n",
      "|I bought a tape of this film based on the recommendation of other IMDb users and have to say that I was very disappoi...|\n",
      "|I usually don't consider turning a movie off unless it's REALLY bad. Homegrown is a movie I wish I hadn't even turned...|\n",
      "|I watched this years ago on television when I was sick (I don't know, I tend to be more complacent with my TV viewing...|\n",
      "|Am I the only one to notice that the \"realism\" of the 19th century ship is erroneous. Actually it's a 15th century, r...|\n",
      "|This movie, despite its list of B, C, and D list celebs, is a complete waste of 90 minutes. The plot, with its few pe...|\n",
      "|To put in simple words or rather a word, would be best suited by PATHETIC !!!!!! The movie starts with attracting a l...|\n",
      "|You may like Tim Burton's fantasies, but not in a commercial-like show off lasting 8 minutes. It demonstrates good te...|\n",
      "|I've expected a comedy about the NVA, but this is a parody. It shows the national army of Eastern Germany in a light ...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100)\n",
    "df.show(truncate=120)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "831bc52c-a5c6-4c29-a6da-0566b5167773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df1 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to German: \")).select(\"input\").limit(100).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46dac59c-5a54-4576-91e0-279c8b375b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fef1d846-5852-4762-8527-602f32c0d7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   input|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|Translate English to German: In following Dylan Moran's star from the charming misanthrope bookstore owner in the sur...|\n",
      "|   Translate English to German: Here in Australia Nights in Rodanthe is being promoted in the same class as the Notebook|\n",
      "|                      Translate English to German: The Tender Hook, or, Who Killed The Australian Film Industry? Case No|\n",
      "|Translate English to German: The only reason I'm even giving this movie a 4 is because it was made in to an episode o...|\n",
      "|Translate English to German: Hooray for Title Misspellings! After reading reviews and contemplating, my girlfriend an...|\n",
      "|                                   Translate English to German: This movie makes you wish imdb would let you vote a zero|\n",
      "|Translate English to German: To me this film is just a very very lame teen party movie with all the normal clichés an...|\n",
      "|                                                                                    Translate English to German: I tried|\n",
      "|          Translate English to German: Awkward disaster mishmash has a team of scavengers coming across the overturned S|\n",
      "|Translate English to German: According to the blurb on the back of the DVD case; Jonothan Ross 'laughed until a littl...|\n",
      "|                      Translate English to German: It'll be a blue Christmas indeed if you subject you're family to this|\n",
      "|Translate English to German: This is the story of a maniac cop who, for some reason, has it in for a young college st...|\n",
      "|Translate English to German: I bought a tape of this film based on the recommendation of other IMDb users and have to...|\n",
      "|                        Translate English to German: I usually don't consider turning a movie off unless it's REALLY bad|\n",
      "|Translate English to German: I watched this years ago on television when I was sick (I don't know, I tend to be more ...|\n",
      "|       Translate English to German: Am I the only one to notice that the \"realism\" of the 19th century ship is erroneous|\n",
      "| Translate English to German: This movie, despite its list of B, C, and D list celebs, is a complete waste of 90 minutes|\n",
      "|Translate English to German: To put in simple words or rather a word, would be best suited by PATHETIC !!!!!! The mov...|\n",
      "|Translate English to German: You may like Tim Burton's fantasies, but not in a commercial-like show off lasting 8 min...|\n",
      "|                                 Translate English to German: I've expected a comedy about the NVA, but this is a parody|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7ae69d3-70c2-4765-928f-c96a7ba59829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    import numpy as np\n",
    "    from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "    def predict(inputs):\n",
    "        flattened = np.squeeze(inputs).tolist()   # convert 2d numpy array of string into flattened python list\n",
    "        input_ids = tokenizer(flattened, \n",
    "                              padding=\"longest\", \n",
    "                              max_length=128,\n",
    "                              return_tensors=\"pt\").input_ids\n",
    "        output_ids = model.generate(input_ids)\n",
    "        string_outputs = np.array([tokenizer.decode(o, skip_special_tokens=True) for o in output_ids])\n",
    "        print(\"predict: {}\".format(len(flattened)))\n",
    "        return string_outputs\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36684f59-d947-43f8-a2e8-c7a423764e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = predict_batch_udf(predict_batch_fn,\n",
    "                             return_type=StringType(),\n",
    "                             batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a01c855-8fa1-4765-a3a5-2c9dd872df10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/rishic/anaconda3/envs/spark-rapids-examples/lib/python3.11/site-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 80.1 ms, sys: 63 ms, total: 143 ms\n",
      "Wall time: 18.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "preds = df1.withColumn(\"preds\", generate(struct(\"input\")))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d912d4b0-cd0b-44ea-859a-b23455cc2700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10                                                         (0 + 1) / 1]\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.1 ms, sys: 62.9 ms, total: 122 ms\n",
      "Wall time: 15.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df1.withColumn(\"preds\", generate(\"input\"))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fe3d88b-30f7-468f-8db8-1f4118d0f26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10                                                         (0 + 1) / 1]\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 69.1 ms, sys: 49.2 ms, total: 118 ms\n",
      "Wall time: 15.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df1.withColumn(\"preds\", generate(col(\"input\")))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ad9b365-4b9a-438e-8fdf-47da55cb1cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10                                                         (0 + 1) / 1]\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       input|                                                       preds|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|Translate English to German: In following Dylan Moran's s...|Indem ich Dylan Morans Star aus dem charmanten Buchhalter...|\n",
      "|Translate English to German: Here in Australia Nights in ...|Hier in Australien Nights in Rodanthe wird in der gleiche...|\n",
      "|Translate English to German: The Tender Hook, or, Who Kil...|The Tender Hook, or, Who Killed The Australian Film Indus...|\n",
      "|Translate English to German: The only reason I'm even giv...|Der einzige Grund, warum ich diesen Film sogar eine 4 ver...|\n",
      "|Translate English to German: Hooray for Title Misspelling...|Nach dem Lesen von Rezensionen und der Überlegung bestäti...|\n",
      "|Translate English to German: This movie makes you wish im...|Dieser Film macht Sie sich wünschen, dass imdb Sie es Ihn...|\n",
      "|Translate English to German: To me this film is just a ve...|Für mich ist dieser Film ein sehr lames Teen Party-Film m...|\n",
      "|                        Translate English to German: I tried|                   Ich habe versucht, Englisch zu übersetzen|\n",
      "|Translate English to German: Awkward disaster mishmash ha...|     Awkward disaster mishmash hat ein Team von Schreckensan|\n",
      "|Translate English to German: According to the blurb on th...|    Laut dem Würfel auf der Rückseite des DVD-Falls hat Jono|\n",
      "|Translate English to German: It'll be a blue Christmas in...|Es wird ein blaues Weihnachtsfest sein, wenn man Ihre Fam...|\n",
      "|Translate English to German: This is the story of a mania...|Diese Geschichte ist die Geschichte eines maniac cop, der...|\n",
      "|Translate English to German: I bought a tape of this film...|Ich habe ein Band dieses Films gekauft, das auf der Empfe...|\n",
      "|Translate English to German: I usually don't consider tur...|Ich erwäge es normalerweise nicht, einen Film aus dem Fer...|\n",
      "|Translate English to German: I watched this years ago on ...|Ich habe dieses Jahr im Fernsehen gesehen, als ich krank ...|\n",
      "|Translate English to German: Am I the only one to notice ...|Am meisten merke ich, dass der \"realistische\" Schiffsbau ...|\n",
      "|Translate English to German: This movie, despite its list...|        Dieser Film, trotz seiner Liste von B, C, und D-Kelb|\n",
      "|Translate English to German: To put in simple words or ra...|Der Film beginnt mit einem kleinen Interesse durch die Ha...|\n",
      "|Translate English to German: You may like Tim Burton's fa...|Tim Burtons Fantasien mag man vielleicht, aber nicht in e...|\n",
      "|Translate English to German: I've expected a comedy about...|Ich habe eine Komödie über die NVA erwartet, aber dies is...|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 204\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds.show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1eb0c83b-d91b-4f8c-a5e7-c35f55c88108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df2 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to French: \")).select(\"input\").limit(100).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "054f94fd-fe79-41e7-b1c7-6124083acc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   input|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|Translate English to French: In following Dylan Moran's star from the charming misanthrope bookstore owner in the sur...|\n",
      "|   Translate English to French: Here in Australia Nights in Rodanthe is being promoted in the same class as the Notebook|\n",
      "|                      Translate English to French: The Tender Hook, or, Who Killed The Australian Film Industry? Case No|\n",
      "|Translate English to French: The only reason I'm even giving this movie a 4 is because it was made in to an episode o...|\n",
      "|Translate English to French: Hooray for Title Misspellings! After reading reviews and contemplating, my girlfriend an...|\n",
      "|                                   Translate English to French: This movie makes you wish imdb would let you vote a zero|\n",
      "|Translate English to French: To me this film is just a very very lame teen party movie with all the normal clichés an...|\n",
      "|                                                                                    Translate English to French: I tried|\n",
      "|          Translate English to French: Awkward disaster mishmash has a team of scavengers coming across the overturned S|\n",
      "|Translate English to French: According to the blurb on the back of the DVD case; Jonothan Ross 'laughed until a littl...|\n",
      "|                      Translate English to French: It'll be a blue Christmas indeed if you subject you're family to this|\n",
      "|Translate English to French: This is the story of a maniac cop who, for some reason, has it in for a young college st...|\n",
      "|Translate English to French: I bought a tape of this film based on the recommendation of other IMDb users and have to...|\n",
      "|                        Translate English to French: I usually don't consider turning a movie off unless it's REALLY bad|\n",
      "|Translate English to French: I watched this years ago on television when I was sick (I don't know, I tend to be more ...|\n",
      "|       Translate English to French: Am I the only one to notice that the \"realism\" of the 19th century ship is erroneous|\n",
      "| Translate English to French: This movie, despite its list of B, C, and D list celebs, is a complete waste of 90 minutes|\n",
      "|Translate English to French: To put in simple words or rather a word, would be best suited by PATHETIC !!!!!! The mov...|\n",
      "|Translate English to French: You may like Tim Burton's fantasies, but not in a commercial-like show off lasting 8 min...|\n",
      "|                                 Translate English to French: I've expected a comedy about the NVA, but this is a parody|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f6b70f9-188a-402b-9143-78a5788140e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/rishic/anaconda3/envs/spark-rapids-examples/lib/python3.11/site-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 76.7 ms, sys: 65 ms, total: 142 ms\n",
      "Wall time: 19.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "preds = df2.withColumn(\"preds\", generate(struct(\"input\")))\n",
    "result = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "031a6a5e-7999-4653-b394-19ed478d8c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10                                                         (0 + 1) / 1]\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.4 ms, sys: 61.3 ms, total: 116 ms\n",
      "Wall time: 15.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df2.withColumn(\"preds\", generate(\"input\"))\n",
    "result = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "229b6515-82f6-4e9c-90f0-a9c3cfb26301",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10                                                         (0 + 1) / 1]\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.4 ms, sys: 71.7 ms, total: 116 ms\n",
      "Wall time: 15.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df2.withColumn(\"preds\", generate(col(\"input\")))\n",
    "result = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8be750ac-fa39-452e-bb4c-c2270bc2f70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10                                                         (0 + 1) / 1]\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       input|                                                       preds|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|Translate English to French: In following Dylan Moran's s...|       En suivant l'étoile de Dylan Moran, tirée du charmant|\n",
      "|Translate English to French: Here in Australia Nights in ...|              Ici, en Australie Nights à Rodanthe, est promu|\n",
      "|Translate English to French: The Tender Hook, or, Who Kil...|The Tender Hook, or, Who Killed The Australian Film Indus...|\n",
      "|Translate English to French: The only reason I'm even giv...|La seule raison pour laquelle je donne même ce film un 4 ...|\n",
      "|Translate English to French: Hooray for Title Misspelling...|Après avoir lu les critiques et réfléchi à la question, m...|\n",
      "|Translate English to French: This movie makes you wish im...|Ce film vous fait envie de voir imdb vous laisser voter zéro|\n",
      "|Translate English to French: To me this film is just a ve...|Pour moi, ce film est un film très lame de teen party ave...|\n",
      "|                        Translate English to French: I tried|                                                 J'ai essayé|\n",
      "|Translate English to French: Awkward disaster mishmash ha...|              Awkward disaster mishmash a eu une équipe de s|\n",
      "|Translate English to French: According to the blurb on th...|                   Selon le brise à l'arrière du cas du DVD,|\n",
      "|Translate English to French: It'll be a blue Christmas in...|Il y aura un Nol bleu en effet si vous soumettez votre fa...|\n",
      "|Translate English to French: This is the story of a mania...|           Voici l'histoire d'un cope maniaque qui, pour une|\n",
      "|Translate English to French: I bought a tape of this film...|        J'ai acheté un bande de ce film en se fondant sur la|\n",
      "|Translate English to French: I usually don't consider tur...|              En général, je ne peux pas mettre un film à l'|\n",
      "|Translate English to French: I watched this years ago on ...|J'ai regardé cette année à la télévision lorsque je suis ...|\n",
      "|Translate English to French: Am I the only one to notice ...|Est-ce que je suis le seul à remarquer que le « réalisme ...|\n",
      "|Translate English to French: This movie, despite its list...|              Ce film, malgré sa liste de cébels de la liste|\n",
      "|Translate English to French: To put in simple words or ra...|Le film commence par attirer un peu d'intérêt par le jeu,...|\n",
      "|Translate English to French: You may like Tim Burton's fa...|Vous aimerez peut-être les fantasies de Tim Burton, mais ...|\n",
      "|Translate English to French: I've expected a comedy about...|          Je m'attendais à ce qu'une comédie sur la NVA soit|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 204\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds.show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcabb2a8-3880-46ec-8e01-5a10f71fe83d",
   "metadata": {},
   "source": [
    "### Using Triton Inference Server\n",
    "\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d98fa52-7665-49bf-865a-feec86effe23",
   "metadata": {},
   "source": [
    "This notebook uses the [Python backend with a custom execution environment](https://github.com/triton-inference-server/python_backend#creating-custom-execution-environments), using a conda-pack environment created as follows:\n",
    "```\n",
    "conda create -n huggingface -c conda-forge python=3.8\n",
    "conda activate huggingface\n",
    "\n",
    "export PYTHONNOUSERSITE=True\n",
    "pip install conda-pack sentencepiece sentence_transformers transformers\n",
    "\n",
    "conda-pack  # huggingface.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b858cf85-82e6-41ef-905b-d8c5d6fea492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05ce7c77-d562-45e8-89bb-cd656aba5a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# copy custom model to expected layout for Triton\n",
    "rm -rf models\n",
    "mkdir -p models\n",
    "cp -r models_config/hf_generation models\n",
    "\n",
    "# add custom execution environment\n",
    "cp huggingface.tar.gz models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a552865c-5dad-4f25-8834-f41e253ac2f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afd00b7e-8150-4c95-a2e4-037e9c90f92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> containers: ['14361b461f08']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_executors = 1\n",
    "triton_models_dir = \"{}/models\".format(os.getcwd())\n",
    "huggingface_cache_dir = \"{}/.cache/huggingface\".format(os.path.expanduser('~'))\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:23.04-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            environment=[\n",
    "                \"TRANSFORMERS_CACHE=/cache\"\n",
    "            ],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"1G\",\n",
    "            volumes={\n",
    "                triton_models_dir: {\"bind\": \"/models\", \"mode\": \"ro\"},\n",
    "                huggingface_cache_dir: {\"bind\": \"/cache\", \"mode\": \"rw\"}\n",
    "            }\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        ready = False\n",
    "        while not ready:\n",
    "            try:\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                time.sleep(5)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528d2df6-49fc-4be7-a534-a087dfe31c84",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a997c33-5202-466d-8304-b8c30f32978f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import partial\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, pandas_udf, struct\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9dea1875-6b95-4fc0-926d-a625a441b33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d6c54e7-534d-406f-b8e6-fd592efd0ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first sentence and add prefix for conditional generation\n",
    "def preprocess(text: pd.Series, prefix: str = \"\") -> pd.Series:\n",
    "    @pandas_udf(\"string\")\n",
    "    def _preprocess(text: pd.Series) -> pd.Series:\n",
    "        return pd.Series([prefix + s.split(\".\")[0] for s in text])\n",
    "    return _preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc1bbbe3-4232-49e5-80f6-99976524b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df1 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to German: \")).select(\"input\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d10c61c-6102-4d19-8dd6-0c7b5b65343e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   input|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|Translate English to German: In following Dylan Moran's star from the charming misanthrope bookstore owner in the sur...|\n",
      "|   Translate English to German: Here in Australia Nights in Rodanthe is being promoted in the same class as the Notebook|\n",
      "|                      Translate English to German: The Tender Hook, or, Who Killed The Australian Film Industry? Case No|\n",
      "|Translate English to German: The only reason I'm even giving this movie a 4 is because it was made in to an episode o...|\n",
      "|Translate English to German: Hooray for Title Misspellings! After reading reviews and contemplating, my girlfriend an...|\n",
      "|                                   Translate English to German: This movie makes you wish imdb would let you vote a zero|\n",
      "|Translate English to German: To me this film is just a very very lame teen party movie with all the normal clichés an...|\n",
      "|                                                                                    Translate English to German: I tried|\n",
      "|          Translate English to German: Awkward disaster mishmash has a team of scavengers coming across the overturned S|\n",
      "|Translate English to German: According to the blurb on the back of the DVD case; Jonothan Ross 'laughed until a littl...|\n",
      "|                      Translate English to German: It'll be a blue Christmas indeed if you subject you're family to this|\n",
      "|Translate English to German: This is the story of a maniac cop who, for some reason, has it in for a young college st...|\n",
      "|Translate English to German: I bought a tape of this film based on the recommendation of other IMDb users and have to...|\n",
      "|                        Translate English to German: I usually don't consider turning a movie off unless it's REALLY bad|\n",
      "|Translate English to German: I watched this years ago on television when I was sick (I don't know, I tend to be more ...|\n",
      "|       Translate English to German: Am I the only one to notice that the \"realism\" of the 19th century ship is erroneous|\n",
      "| Translate English to German: This movie, despite its list of B, C, and D list celebs, is a complete waste of 90 minutes|\n",
      "|Translate English to German: To put in simple words or rather a word, would be best suited by PATHETIC !!!!!! The mov...|\n",
      "|Translate English to German: You may like Tim Burton's fantasies, but not in a commercial-like show off lasting 8 min...|\n",
      "|                                 Translate English to German: I've expected a comedy about the NVA, but this is a parody|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e0907da-a5d9-4c3b-9db4-ce5e70ca9bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool8),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name()].astype(np_types[i.datatype()]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        \n",
    "        if len(model_meta.outputs) > 1:\n",
    "            # return dictionary of numpy arrays\n",
    "            return {o.name: response.as_numpy(o.name) for o in model_meta.outputs}\n",
    "        else:\n",
    "            # return single numpy array\n",
    "            return response.as_numpy(model_meta.outputs[0].name)\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9308bdd7-6f67-484d-8b51-dd1e1b2960ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = predict_batch_udf(partial(triton_fn, triton_uri=\"localhost:8001\", model_name=\"hf_generation\"),\n",
    "                             return_type=StringType(),\n",
    "                             input_tensor_shapes=[[1]],\n",
    "                             batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38484ffd-370d-492b-8ca4-9eff9f242a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2124884/3110230631.py:6: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 ms, sys: 31.6 ms, total: 47.2 ms\n",
      "Wall time: 5.13 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "preds = df1.withColumn(\"preds\", generate(struct(\"input\")))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ebcb6699-3ac2-4529-ab0f-fab0a5e792da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 ms, sys: 22 ms, total: 41.9 ms\n",
      "Wall time: 4.52 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df1.withColumn(\"preds\", generate(\"input\"))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2ed18ad-d00b-472c-b2c3-047932f2105d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 49:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.11 ms, sys: 34.1 ms, total: 42.3 ms\n",
      "Wall time: 4.52 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df1.withColumn(\"preds\", generate(col(\"input\")))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0cd64a1c-beb8-47d5-ac6f-e8525bb61176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       input|                                                       preds|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|Translate English to German: In following Dylan Moran's s...|Indem ich Dylan Morans Star aus dem charmanten Buchhalter...|\n",
      "|Translate English to German: Here in Australia Nights in ...|Hier in Australien Nights in Rodanthe wird in der gleiche...|\n",
      "|Translate English to German: The Tender Hook, or, Who Kil...|The Tender Hook, or, Who Killed The Australian Film Indus...|\n",
      "|Translate English to German: The only reason I'm even giv...|Der einzige Grund, warum ich diesen Film sogar eine 4 ver...|\n",
      "|Translate English to German: Hooray for Title Misspelling...|Nach dem Lesen von Rezensionen und der Überlegung bestäti...|\n",
      "|Translate English to German: This movie makes you wish im...|Dieser Film macht Sie sich wünschen, dass imdb Sie es Ihn...|\n",
      "|Translate English to German: To me this film is just a ve...|Für mich ist dieser Film ein sehr lames Teen Party-Film m...|\n",
      "|                        Translate English to German: I tried|                   Ich habe versucht, Englisch zu übersetzen|\n",
      "|Translate English to German: Awkward disaster mishmash ha...|     Awkward disaster mishmash hat ein Team von Schreckensan|\n",
      "|Translate English to German: According to the blurb on th...|    Laut dem Würfel auf der Rückseite des DVD-Falls hat Jono|\n",
      "|Translate English to German: It'll be a blue Christmas in...|Es wird ein blaues Weihnachtsfest sein, wenn man Ihre Fam...|\n",
      "|Translate English to German: This is the story of a mania...|Diese Geschichte ist die Geschichte eines maniac cop, der...|\n",
      "|Translate English to German: I bought a tape of this film...|Ich habe ein Band dieses Films gekauft, das auf der Empfe...|\n",
      "|Translate English to German: I usually don't consider tur...|Ich erwäge es normalerweise nicht, einen Film aus dem Fer...|\n",
      "|Translate English to German: I watched this years ago on ...|Ich habe dieses Jahr im Fernsehen gesehen, als ich krank ...|\n",
      "|Translate English to German: Am I the only one to notice ...|Am meisten merke ich, dass der \"realistische\" Schiffsbau ...|\n",
      "|Translate English to German: This movie, despite its list...|        Dieser Film, trotz seiner Liste von B, C, und D-Kelb|\n",
      "|Translate English to German: To put in simple words or ra...|Der Film beginnt mit einem kleinen Interesse durch die Ha...|\n",
      "|Translate English to German: You may like Tim Burton's fa...|Tim Burtons Fantasien mag man vielleicht, aber nicht in e...|\n",
      "|Translate English to German: I've expected a comedy about...|Ich habe eine Komödie über die NVA erwartet, aber dies is...|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds.show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "af70fed8-0f2b-4ea7-841c-476afdf9b1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/18 18:06:42 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df2 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to French: \")).select(\"input\").limit(100).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef075e10-e22c-4236-9e0b-cb47cf2d3d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   input|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|Translate English to French: In following Dylan Moran's star from the charming misanthrope bookstore owner in the sur...|\n",
      "|   Translate English to French: Here in Australia Nights in Rodanthe is being promoted in the same class as the Notebook|\n",
      "|                      Translate English to French: The Tender Hook, or, Who Killed The Australian Film Industry? Case No|\n",
      "|Translate English to French: The only reason I'm even giving this movie a 4 is because it was made in to an episode o...|\n",
      "|Translate English to French: Hooray for Title Misspellings! After reading reviews and contemplating, my girlfriend an...|\n",
      "|                                   Translate English to French: This movie makes you wish imdb would let you vote a zero|\n",
      "|Translate English to French: To me this film is just a very very lame teen party movie with all the normal clichés an...|\n",
      "|                                                                                    Translate English to French: I tried|\n",
      "|          Translate English to French: Awkward disaster mishmash has a team of scavengers coming across the overturned S|\n",
      "|Translate English to French: According to the blurb on the back of the DVD case; Jonothan Ross 'laughed until a littl...|\n",
      "|                      Translate English to French: It'll be a blue Christmas indeed if you subject you're family to this|\n",
      "|Translate English to French: This is the story of a maniac cop who, for some reason, has it in for a young college st...|\n",
      "|Translate English to French: I bought a tape of this film based on the recommendation of other IMDb users and have to...|\n",
      "|                        Translate English to French: I usually don't consider turning a movie off unless it's REALLY bad|\n",
      "|Translate English to French: I watched this years ago on television when I was sick (I don't know, I tend to be more ...|\n",
      "|       Translate English to French: Am I the only one to notice that the \"realism\" of the 19th century ship is erroneous|\n",
      "| Translate English to French: This movie, despite its list of B, C, and D list celebs, is a complete waste of 90 minutes|\n",
      "|Translate English to French: To put in simple words or rather a word, would be best suited by PATHETIC !!!!!! The mov...|\n",
      "|Translate English to French: You may like Tim Burton's fantasies, but not in a commercial-like show off lasting 8 min...|\n",
      "|                                 Translate English to French: I've expected a comedy about the NVA, but this is a parody|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2e7e4af8-b815-4375-b851-8368309ee8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2124884/3110230631.py:6: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.4 ms, sys: 28.9 ms, total: 47.3 ms\n",
      "Wall time: 5.19 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df2.withColumn(\"preds\", generate(struct(\"input\")))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b0aefb0-a96b-4791-a23c-1ce9b24eb20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.2 ms, sys: 22.8 ms, total: 41 ms\n",
      "Wall time: 4.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df2.withColumn(\"preds\", generate(\"input\"))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1214b75b-a373-4579-b4c6-0cb8627da776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 59:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.9 ms, sys: 19.5 ms, total: 39.4 ms\n",
      "Wall time: 4.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df2.withColumn(\"preds\", generate(col(\"input\")))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c9dbd21f-9e37-4221-b765-80ba8c80b884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       input|                                                       preds|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|Translate English to French: In following Dylan Moran's s...|       En suivant l'étoile de Dylan Moran, tirée du charmant|\n",
      "|Translate English to French: Here in Australia Nights in ...|              Ici, en Australie Nights à Rodanthe, est promu|\n",
      "|Translate English to French: The Tender Hook, or, Who Kil...|The Tender Hook, or, Who Killed The Australian Film Indus...|\n",
      "|Translate English to French: The only reason I'm even giv...|La seule raison pour laquelle je donne même ce film un 4 ...|\n",
      "|Translate English to French: Hooray for Title Misspelling...|Après avoir lu les critiques et réfléchi à la question, m...|\n",
      "|Translate English to French: This movie makes you wish im...|Ce film vous fait envie de voir imdb vous laisser voter zéro|\n",
      "|Translate English to French: To me this film is just a ve...|Pour moi, ce film est un film très lame de teen party ave...|\n",
      "|                        Translate English to French: I tried|                                                 J'ai essayé|\n",
      "|Translate English to French: Awkward disaster mishmash ha...|              Awkward disaster mishmash a eu une équipe de s|\n",
      "|Translate English to French: According to the blurb on th...|                   Selon le brise à l'arrière du cas du DVD,|\n",
      "|Translate English to French: It'll be a blue Christmas in...|Il y aura un Nol bleu en effet si vous soumettez votre fa...|\n",
      "|Translate English to French: This is the story of a mania...|           Voici l'histoire d'un cope maniaque qui, pour une|\n",
      "|Translate English to French: I bought a tape of this film...|        J'ai acheté un bande de ce film en se fondant sur la|\n",
      "|Translate English to French: I usually don't consider tur...|              En général, je ne peux pas mettre un film à l'|\n",
      "|Translate English to French: I watched this years ago on ...|J'ai regardé cette année à la télévision lorsque je suis ...|\n",
      "|Translate English to French: Am I the only one to notice ...|Est-ce que je suis le seul à remarquer que le « réalisme ...|\n",
      "|Translate English to French: This movie, despite its list...|              Ce film, malgré sa liste de cébels de la liste|\n",
      "|Translate English to French: To put in simple words or ra...|Le film commence par attirer un peu d'intérêt par le jeu,...|\n",
      "|Translate English to French: You may like Tim Burton's fa...|Vous aimerez peut-être les fantasies de Tim Burton, mais ...|\n",
      "|Translate English to French: I've expected a comedy about...|          Je m'attendais à ce qu'une comédie sur la NVA soit|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds.show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919e3113-64dd-482a-9233-6607b3f63c1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "425d3b28-7705-45ba-8a18-ad34fc895219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> stopping containers: ['14361b461f08']\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2dec80ca-7a7c-46a9-97c0-7afb1572f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43118ab-fc0a-4f64-a126-4302e615654a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
