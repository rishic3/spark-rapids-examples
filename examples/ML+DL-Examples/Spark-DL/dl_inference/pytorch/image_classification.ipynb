{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e87c927",
   "metadata": {},
   "source": [
    "# PySpark PyTorch Inference\n",
    "\n",
    "### Image Classification\n",
    "Based on: https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d7ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d714f40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c942a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:02<00:00, 11595082.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 165746.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:01<00:00, 3671121.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 16790262.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a89aa8e-ef62-4aac-8260-4b004f2c1b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a97111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28]) torch.float32\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape} {X.dtype}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7af350",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "512d0bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573c1b7",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d4f5538",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92d9076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11c5650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "854608e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.302510  [    0/60000]\n",
      "loss: 2.290746  [ 6400/60000]\n",
      "loss: 2.273581  [12800/60000]\n",
      "loss: 2.270329  [19200/60000]\n",
      "loss: 2.254656  [25600/60000]\n",
      "loss: 2.228528  [32000/60000]\n",
      "loss: 2.238483  [38400/60000]\n",
      "loss: 2.210059  [44800/60000]\n",
      "loss: 2.197927  [51200/60000]\n",
      "loss: 2.178862  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 2.171240 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.172268  [    0/60000]\n",
      "loss: 2.162264  [ 6400/60000]\n",
      "loss: 2.116437  [12800/60000]\n",
      "loss: 2.137667  [19200/60000]\n",
      "loss: 2.081341  [25600/60000]\n",
      "loss: 2.028898  [32000/60000]\n",
      "loss: 2.055932  [38400/60000]\n",
      "loss: 1.986404  [44800/60000]\n",
      "loss: 1.982685  [51200/60000]\n",
      "loss: 1.927453  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 1.922579 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.943846  [    0/60000]\n",
      "loss: 1.917159  [ 6400/60000]\n",
      "loss: 1.812734  [12800/60000]\n",
      "loss: 1.857640  [19200/60000]\n",
      "loss: 1.737204  [25600/60000]\n",
      "loss: 1.690268  [32000/60000]\n",
      "loss: 1.713811  [38400/60000]\n",
      "loss: 1.620650  [44800/60000]\n",
      "loss: 1.635345  [51200/60000]\n",
      "loss: 1.532983  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.7%, Avg loss: 1.551843 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.613954  [    0/60000]\n",
      "loss: 1.575798  [ 6400/60000]\n",
      "loss: 1.430596  [12800/60000]\n",
      "loss: 1.499834  [19200/60000]\n",
      "loss: 1.368976  [25600/60000]\n",
      "loss: 1.365644  [32000/60000]\n",
      "loss: 1.377686  [38400/60000]\n",
      "loss: 1.310158  [44800/60000]\n",
      "loss: 1.338419  [51200/60000]\n",
      "loss: 1.228369  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 1.265753 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.346443  [    0/60000]\n",
      "loss: 1.321508  [ 6400/60000]\n",
      "loss: 1.158795  [12800/60000]\n",
      "loss: 1.257129  [19200/60000]\n",
      "loss: 1.129951  [25600/60000]\n",
      "loss: 1.156021  [32000/60000]\n",
      "loss: 1.171372  [38400/60000]\n",
      "loss: 1.119799  [44800/60000]\n",
      "loss: 1.153165  [51200/60000]\n",
      "loss: 1.056943  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 1.091811 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d97839",
   "metadata": {},
   "source": [
    "### Save Model State Dict\n",
    "This is the [currently recommended save format](https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d5d24de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model_weights.pt\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model_weights.pt\")\n",
    "print(\"Saved PyTorch Model State to model_weights.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416bbef",
   "metadata": {},
   "source": [
    "### Save Entire Model\n",
    "This saves the entire model using python pickle, but has the [following disadvantage](https://pytorch.org/tutorials/beginner/saving_loading_models.html#save-load-entire-model):\n",
    "> The serialized data is bound to the specific classes and the exact directory structure used when the model is saved... Because of this, your code can break in various ways when used in other projects or after refactors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e87098c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac221ca7-e227-4c8c-8577-1eeda4a61fc7",
   "metadata": {},
   "source": [
    "### Save Model as TorchScript\n",
    "This saves an [intermediate representation of the compute graph](https://pytorch.org/tutorials/beginner/saving_loading_models.html#export-load-model-in-torchscript-format), which does not require pickle (or even python).  However, this currently doesn't work with spark, which uses pickle serialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d9b3a45-7618-43e4-8bd3-8bb317a484d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted = torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cd01550-c72e-47f2-abe6-e14f26b06fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scripted.save(\"model.ts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee8916-f437-4a2a-9bf4-14ff5376d305",
   "metadata": {},
   "source": [
    "### Load Model State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fe3b5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3595264/2512044506.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_from_state.load_state_dict(torch.load(\"model_weights.pt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_from_state = NeuralNetwork()\n",
    "model_from_state.load_state_dict(torch.load(\"model_weights.pt\")) # Load model weights to CPU by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c405bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "model_from_state.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model_from_state(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1708f5e0",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc5bce69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3595264/39731073.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  new_model = torch.load(\"model.pt\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model to original device (GPU) and move to CPU. \n",
    "new_model = torch.load(\"model.pt\") \n",
    "new_model.to(\"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc219a56-4abd-4b61-9f9a-686dae7c9614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = new_model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c482a-1c5d-4bf2-bc3f-8a4e53d442b5",
   "metadata": {},
   "source": [
    "### Load Torchscript Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef3c419e-d384-446c-b07b-1af93e07d6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=NeuralNetwork\n",
       "  (flatten): RecursiveScriptModule(original_name=Flatten)\n",
       "  (linear_relu_stack): RecursiveScriptModule(\n",
       "    original_name=Sequential\n",
       "    (0): RecursiveScriptModule(original_name=Linear)\n",
       "    (1): RecursiveScriptModule(original_name=ReLU)\n",
       "    (2): RecursiveScriptModule(original_name=Linear)\n",
       "    (3): RecursiveScriptModule(original_name=ReLU)\n",
       "    (4): RecursiveScriptModule(original_name=Linear)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model to original device (GPU) and move to CPU. \n",
    "ts_model = torch.jit.load(\"model.ts\")\n",
    "ts_model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "038af830-a360-45eb-ab4e-b1adab0af164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = ts_model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad918393",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1daec3",
   "metadata": {},
   "source": [
    "### Convert numpy dataset to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42c5feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f063cbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = test_data.data.numpy()\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c828393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), dtype('float64'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reshape(10000, 784) / 255.0\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7760bdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2         3    4         5         6    7         8    \\\n",
       "0     0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "1     0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "2     0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.003922   \n",
       "3     0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "4     0.0  0.0  0.0  0.007843  0.0  0.003922  0.003922  0.0  0.000000   \n",
       "...   ...  ...  ...       ...  ...       ...       ...  ...       ...   \n",
       "9995  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "9996  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "9997  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "9998  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "9999  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "\n",
       "           9    ...       774       775  776       777       778       779  \\\n",
       "0     0.000000  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "1     0.000000  ...  0.007843  0.011765  0.0  0.011765  0.682353  0.741176   \n",
       "2     0.000000  ...  0.643137  0.227451  0.0  0.000000  0.000000  0.000000   \n",
       "3     0.082353  ...  0.003922  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "4     0.000000  ...  0.278431  0.047059  0.0  0.000000  0.000000  0.000000   \n",
       "...        ...  ...       ...       ...  ...       ...       ...       ...   \n",
       "9995  0.000000  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "9996  0.121569  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "9997  0.000000  ...  0.105882  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "9998  0.000000  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "9999  0.000000  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "           780  781  782  783  \n",
       "0     0.000000  0.0  0.0  0.0  \n",
       "1     0.262745  0.0  0.0  0.0  \n",
       "2     0.000000  0.0  0.0  0.0  \n",
       "3     0.000000  0.0  0.0  0.0  \n",
       "4     0.000000  0.0  0.0  0.0  \n",
       "...        ...  ...  ...  ...  \n",
       "9995  0.000000  0.0  0.0  0.0  \n",
       "9996  0.000000  0.0  0.0  0.0  \n",
       "9997  0.000000  0.0  0.0  0.0  \n",
       "9998  0.000000  0.0  0.0  0.0  \n",
       "9999  0.000000  0.0  0.0  0.0  \n",
       "\n",
       "[10000 rows x 784 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf784 = pd.DataFrame(data)\n",
    "pdf784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7d2bc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 173 ms, sys: 56.2 ms, total: 229 ms\n",
      "Wall time: 228 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.00784313725490196, 0.0, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   data\n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003...\n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4     [0.0, 0.0, 0.0, 0.00784313725490196, 0.0, 0.00...\n",
       "...                                                 ...\n",
       "9995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 1 column of array<float>\n",
    "pdf1 = pd.DataFrame()\n",
    "pdf1['data'] = pdf784.values.tolist()\n",
    "pdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20c3b86a-8b61-4128-ab61-0199fd3437cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Spark DataFrame from Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a5d7ccf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/16 15:27:59 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "num_threads = 6\n",
    "\n",
    "_config = {\n",
    "    \"spark.master\": f\"local[{num_threads}]\",\n",
    "    \"spark.driver.host\": \"127.0.0.1\",\n",
    "    \"spark.task.maxFailures\": \"1\",\n",
    "    \"spark.driver.memory\": \"8g\",\n",
    "    \"spark.executor.memory\": \"8g\",\n",
    "    \"spark.sql.execution.pyspark.udf.simplifiedTraceback.enabled\": \"false\",\n",
    "    \"spark.sql.pyspark.jvmStacktrace.enabled\": \"true\",\n",
    "    \"spark.sql.execution.arrow.pyspark.enabled\": \"true\",\n",
    "}\n",
    "spark = SparkSession.builder.appName(\"spark-dl-example\")\n",
    "for key, value in _config.items():\n",
    "    spark = spark.config(key, value)\n",
    "spark = spark.getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4863d5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 217 ms, sys: 60.2 ms, total: 277 ms\n",
      "Wall time: 2.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# force FloatType since Spark defaults to DoubleType\n",
    "schema = StructType([StructField(\"data\",ArrayType(FloatType()), True)])\n",
    "df = spark.createDataFrame(pdf1, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "406edba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('data', ArrayType(FloatType(), True), True)])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "831f4a01-3a49-4114-b9a0-2ae54526d72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 175 ms, sys: 56.4 ms, total: 231 ms\n",
      "Wall time: 1.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# force FloatType since Spark defaults to DoubleType\n",
    "schema = StructType([StructField(str(x), FloatType(), True) for x in range(784)])\n",
    "df784 = spark.createDataFrame(pdf784, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c7448",
   "metadata": {},
   "source": [
    "### Save the test dataset as parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8ebae46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/16 15:03:19 WARN TaskSetManager: Stage 0 contains a task of very large size (5369 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 0:>                                                          (0 + 6) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.89 ms, sys: 0 ns, total: 7.89 ms\n",
      "Wall time: 1.89 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.write.mode(\"overwrite\").parquet(\"fashion_mnist_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "922314ce-2996-4666-9fc9-bcd98d16bb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/16 15:03:24 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "24/09/16 15:03:25 WARN TaskSetManager: Stage 1 contains a task of very large size (10457 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 1:>                                                          (0 + 6) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.02 ms, sys: 363 μs, total: 8.39 ms\n",
      "Wall time: 1.55 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df784.write.mode(\"overwrite\").parquet(\"fashion_mnist_784\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8688429e",
   "metadata": {},
   "source": [
    "### Check arrow memory configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "088cb37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"128\")\n",
    "# This line will fail if the vectorized reader runs out of memory\n",
    "assert len(df.head()) > 0, \"`df` should not be empty\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c77eb4-7bd6-40c7-9a35-ee899a66ece3",
   "metadata": {},
   "source": [
    "## Inference using Spark DL API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59395856-a588-43c6-93c8-c83100716ac1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1 columns of 784 float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "133cc9a5-64c6-4820-807e-b87cf7e0b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct, col, array\n",
    "from pyspark.sql.types import ArrayType, FloatType, Union, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "79b151d9-d112-43b6-a479-887e2fd0e2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet(\"fashion_mnist_1\")\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cabcd546-2e8e-40d0-8b79-7598a7a83aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('data', ArrayType(FloatType(), True), True)])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5db4b957-57fc-4bc5-b8bb-db0657a186c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get absolute path to model\n",
    "model_dir = \"{}/model.ts\".format(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "73dc73cb-25e3-4798-a019-e1abd684eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    import torch\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Using {} device\".format(device))\n",
    "    model = torch.jit.load(model_dir)\n",
    "    model.to(device)\n",
    "    \n",
    "    def predict(inputs: np.ndarray):\n",
    "        torch_inputs = torch.from_numpy(inputs).to(device)\n",
    "        outputs = model(torch_inputs)\n",
    "        return outputs.detach().cpu().numpy()\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df68cca1-2d47-4e88-8aad-9899402aee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = predict_batch_udf(predict_batch_fn,\n",
    "                          input_tensor_shapes=[[784]],\n",
    "                          return_type=ArrayType(FloatType()),\n",
    "                          batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "63555b3b-3673-4712-97aa-fd728c6c4979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Using cuda device\n",
      "Using cuda device\n",
      "Using cuda device\n",
      "Using cuda device\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 762 ms, sys: 128 ms, total: 891 ms\n",
      "Wall time: 1.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "preds = df.withColumn(\"preds\", mnist(struct(df.columns))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5dbf058a-70d6-4199-af9d-13843d078950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 536 ms, sys: 101 ms, total: 637 ms\n",
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*df.columns)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3f5ed801-6ca5-43a0-bf9c-2535a0dfe2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 443 ms, sys: 135 ms, total: 578 ms\n",
      "Wall time: 1.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*[col(c) for c in df.columns])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dbec03-9b64-46c4-a748-f889be571384",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f1f1e5fd-5866-4b78-b9d3-709e6b383a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = preds[0].preds\n",
    "img = preds[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "76b76502-adb7-45ec-a365-2e61cdd576fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c163953a-1504-444f-b39f-86b61d34e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img).reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bc0fad05-50ab-4ae5-b9fd-e50133c4c92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "56f36efb-e3a2-49f9-b9fb-1657bc25e5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.8384504318237305, 1.2933310270309448, 1.3286985158920288, 2.6207523345947266, 1.4957536458969116, -3.2776546478271484, 2.257317304611206, -4.6599555015563965, -1.1901979446411133, -2.866666078567505]\n",
      "predicted label: T-shirt/top\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(\"predicted label:\", classes[np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ca1195-ea0f-405f-87fe-857e5c0c76a5",
   "metadata": {},
   "source": [
    "### 784 columns of float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e0ab0af6-b5c9-4b74-9dd6-baa7737cc986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet(\"fashion_mnist_784\")\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "13ae45dc-85a0-4864-8a58-9dc29ae4efd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda device                                                   (0 + 6) / 6]\n",
      "Using cuda device\n",
      "Using cuda device\n",
      "Using cuda device\n",
      "Using cuda device\n",
      "Using cuda device\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 684 ms, sys: 123 ms, total: 807 ms\n",
      "Wall time: 8.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(struct(df.columns))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0b3fb48b-f871-41f2-ac57-346899a6fe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.02 s, sys: 123 ms, total: 1.14 s\n",
      "Wall time: 2.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(array(*df.columns))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc48ec42-0df6-4e6a-b019-1270ab71d2cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d815c701-9f5b-422c-b3f9-fbc30456953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = df.withColumn(\"preds\", mnist(array(*df.columns))).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b571b742-5079-42b2-8524-9181a0dec2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = preds.iloc[0]\n",
    "predictions = sample.preds\n",
    "img = sample.drop('preds').to_numpy(dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d33d6a4e-e6b9-489d-ac21-c4eddc801784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6d10061e-aca6-4f81-bdfe-72e327ed7349",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img).reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "01f70e08-2c1d-419f-8676-3f6f4aba760f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8e1c07cc-b2bc-4902-a9a6-4ac7f02c5fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.83845    1.2933313  1.3286985  2.6207523  1.4957536 -3.277655\n",
      "  2.2573178 -4.6599555 -1.1901978 -2.866666 ]\n",
      "predicted label: T-shirt/top\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(\"predicted label:\", classes[np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a937adc9-508d-4ccd-b92d-8ecaa27ee4e4",
   "metadata": {},
   "source": [
    "### Using Triton Inference Server\n",
    "\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "53ca290a-ccc3-4923-a292-944921bab36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct, col, array\n",
    "from pyspark.sql.types import ArrayType, FloatType, Union, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8fa92fe4-2e04-4d82-a357-bfdfca38bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# copy model to expected layout for Triton\n",
    "rm -rf models\n",
    "mkdir -p models/fashion_mnist/1\n",
    "cp model.ts models/fashion_mnist/1/model.pt\n",
    "\n",
    "# add config.pbtxt\n",
    "cp models_config/fashion_mnist/config.pbtxt models/fashion_mnist/config.pbtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42b329c-5921-436f-bfca-a382a6762da4",
   "metadata": {},
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5e869730-3597-4074-bab0-f87768f8996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/16 15:28:08 ERROR Executor: Exception in task 0.0 in stage 16.0 (TID 76)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 495, in _make_request\n",
      "    conn.request(\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connection.py\", line 441, in request\n",
      "    self.endheaders()\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 1298, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 1058, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 996, in send\n",
      "    self.connect()\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/transport/unixconn.py\", line 26, in connect\n",
      "    sock.connect(self.unix_socket)\n",
      "PermissionError: [Errno 13] Permission denied\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/util/retry.py\", line 474, in increment\n",
      "    raise reraise(type(error), error, _stacktrace)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/util/util.py\", line 38, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 495, in _make_request\n",
      "    conn.request(\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connection.py\", line 441, in request\n",
      "    self.endheaders()\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 1298, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 1058, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 996, in send\n",
      "    self.connect()\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/transport/unixconn.py\", line 26, in connect\n",
      "    sock.connect(self.unix_socket)\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', PermissionError(13, 'Permission denied'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/api/client.py\", line 223, in _retrieve_server_version\n",
      "    return self.version(api_version=False)[\"ApiVersion\"]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/api/daemon.py\", line 181, in version\n",
      "    return self._result(self._get(url), json=True)\n",
      "                        ^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/utils/decorators.py\", line 44, in inner\n",
      "    return f(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/api/client.py\", line 246, in _get\n",
      "    return self.get(url, **self._set_request_timeout(kwargs))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/requests/sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/requests/adapters.py\", line 682, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', PermissionError(13, 'Permission denied'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 830, in main\n",
      "    process()\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 820, in process\n",
      "    out_iter = func(split_index, iterator)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/pyspark/rdd.py\", line 5314, in func\n",
      "    return f(iterator)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_3595264/14439956.py\", line 10, in start_triton\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/client.py\", line 94, in from_env\n",
      "    return cls(\n",
      "           ^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/client.py\", line 45, in __init__\n",
      "    self.api = APIClient(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/api/client.py\", line 207, in __init__\n",
      "    self._version = self._retrieve_server_version()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/api/client.py\", line 230, in _retrieve_server_version\n",
      "    raise DockerException(\n",
      "docker.errors.DockerException: Error while fetching server API version: ('Connection aborted.', PermissionError(13, 'Permission denied'))\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:561)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:767)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:749)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:514)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1022)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2303)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/09/16 15:28:08 WARN TaskSetManager: Lost task 0.0 in stage 16.0 (TID 76) (jinfengl-dt.nvidia.com executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 495, in _make_request\n",
      "    conn.request(\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connection.py\", line 441, in request\n",
      "    self.endheaders()\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 1298, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 1058, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 996, in send\n",
      "    self.connect()\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/transport/unixconn.py\", line 26, in connect\n",
      "    sock.connect(self.unix_socket)\n",
      "PermissionError: [Errno 13] Permission denied\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/util/retry.py\", line 474, in increment\n",
      "    raise reraise(type(error), error, _stacktrace)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/util/util.py\", line 38, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 495, in _make_request\n",
      "    conn.request(\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connection.py\", line 441, in request\n",
      "    self.endheaders()\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 1298, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 1058, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 996, in send\n",
      "    self.connect()\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/transport/unixconn.py\", line 26, in connect\n",
      "    sock.connect(self.unix_socket)\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', PermissionError(13, 'Permission denied'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/api/client.py\", line 223, in _retrieve_server_version\n",
      "    return self.version(api_version=False)[\"ApiVersion\"]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/api/daemon.py\", line 181, in version\n",
      "    return self._result(self._get(url), json=True)\n",
      "                        ^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/utils/decorators.py\", line 44, in inner\n",
      "    return f(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/api/client.py\", line 246, in _get\n",
      "    return self.get(url, **self._set_request_timeout(kwargs))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/requests/sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/requests/adapters.py\", line 682, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', PermissionError(13, 'Permission denied'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 830, in main\n",
      "    process()\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 820, in process\n",
      "    out_iter = func(split_index, iterator)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/pyspark/rdd.py\", line 5314, in func\n",
      "    return f(iterator)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_3595264/14439956.py\", line 10, in start_triton\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/client.py\", line 94, in from_env\n",
      "    return cls(\n",
      "           ^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/client.py\", line 45, in __init__\n",
      "    self.api = APIClient(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/api/client.py\", line 207, in __init__\n",
      "    self._version = self._retrieve_server_version()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/api/client.py\", line 230, in _retrieve_server_version\n",
      "    raise DockerException(\n",
      "docker.errors.DockerException: Error while fetching server API version: ('Connection aborted.', PermissionError(13, 'Permission denied'))\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:561)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:767)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:749)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:514)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1022)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2303)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Could not recover from a failed barrier ResultStage. Most recent failure reason: Stage failed because barrier task ResultTask(16, 0) finished unsuccessfully.\norg.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 789, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 495, in _make_request\n    conn.request(\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connection.py\", line 441, in request\n    self.endheaders()\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 1298, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 1058, in _send_output\n    self.send(msg)\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 996, in send\n    self.connect()\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/transport/unixconn.py\", line 26, in connect\n    sock.connect(self.unix_socket)\nPermissionError: [Errno 13] Permission denied\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/requests/adapters.py\", line 667, in send\n    resp = conn.urlopen(\n           ^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 843, in urlopen\n    retries = retries.increment(\n              ^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/util/retry.py\", line 474, in increment\n    raise reraise(type(error), error, _stacktrace)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/util/util.py\", line 38, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 789, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 495, in _make_request\n    conn.request(\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connection.py\", line 441, in request\n    self.endheaders()\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 1298, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 1058, in _send_output\n    self.send(msg)\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 996, in send\n    self.connect()\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/transport/unixconn.py\", line 26, in connect\n    sock.connect(self.unix_socket)\nurllib3.exceptions.ProtocolError: ('Connection aborted.', PermissionError(13, 'Permission denied'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/api/client.py\", line 223, in _retrieve_server_version\n    return self.version(api_version=False)[\"ApiVersion\"]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/api/daemon.py\", line 181, in version\n    return self._result(self._get(url), json=True)\n                        ^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/utils/decorators.py\", line 44, in inner\n    return f(self, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/api/client.py\", line 246, in _get\n    return self.get(url, **self._set_request_timeout(kwargs))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/requests/sessions.py\", line 602, in get\n    return self.request(\"GET\", url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/requests/adapters.py\", line 682, in send\n    raise ConnectionError(err, request=request)\nrequests.exceptions.ConnectionError: ('Connection aborted.', PermissionError(13, 'Permission denied'))\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 830, in main\n    process()\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 820, in process\n    out_iter = func(split_index, iterator)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/pyspark/rdd.py\", line 5314, in func\n    return f(iterator)\n           ^^^^^^^^^^^\n  File \"/tmp/ipykernel_3595264/14439956.py\", line 10, in start_triton\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/client.py\", line 94, in from_env\n    return cls(\n           ^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/client.py\", line 45, in __init__\n    self.api = APIClient(*args, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/api/client.py\", line 207, in __init__\n    self._version = self._retrieve_server_version()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/api/client.py\", line 230, in _retrieve_server_version\n    raise DockerException(\ndocker.errors.DockerException: Error while fetching server API version: ('Connection aborted.', PermissionError(13, 'Permission denied'))\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:561)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:767)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:749)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:514)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1022)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2303)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:2163)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2263)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2328)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1022)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1021)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 39\u001b[0m\n\u001b[1;32m     35\u001b[0m                 time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;01mTrue\u001b[39;00m]\n\u001b[0;32m---> 39\u001b[0m \u001b[43mnodeRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbarrier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_triton\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/pyspark/rdd.py:1814\u001b[0m, in \u001b[0;36mRDD.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1812\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext):\n\u001b[1;32m   1813\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1814\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Could not recover from a failed barrier ResultStage. Most recent failure reason: Stage failed because barrier task ResultTask(16, 0) finished unsuccessfully.\norg.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 789, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 495, in _make_request\n    conn.request(\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connection.py\", line 441, in request\n    self.endheaders()\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 1298, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 1058, in _send_output\n    self.send(msg)\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 996, in send\n    self.connect()\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/transport/unixconn.py\", line 26, in connect\n    sock.connect(self.unix_socket)\nPermissionError: [Errno 13] Permission denied\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/requests/adapters.py\", line 667, in send\n    resp = conn.urlopen(\n           ^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 843, in urlopen\n    retries = retries.increment(\n              ^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/util/retry.py\", line 474, in increment\n    raise reraise(type(error), error, _stacktrace)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/util/util.py\", line 38, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 789, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 495, in _make_request\n    conn.request(\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/urllib3/connection.py\", line 441, in request\n    self.endheaders()\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 1298, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 1058, in _send_output\n    self.send(msg)\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/http/client.py\", line 996, in send\n    self.connect()\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/transport/unixconn.py\", line 26, in connect\n    sock.connect(self.unix_socket)\nurllib3.exceptions.ProtocolError: ('Connection aborted.', PermissionError(13, 'Permission denied'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/api/client.py\", line 223, in _retrieve_server_version\n    return self.version(api_version=False)[\"ApiVersion\"]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/api/daemon.py\", line 181, in version\n    return self._result(self._get(url), json=True)\n                        ^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/utils/decorators.py\", line 44, in inner\n    return f(self, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/api/client.py\", line 246, in _get\n    return self.get(url, **self._set_request_timeout(kwargs))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/requests/sessions.py\", line 602, in get\n    return self.request(\"GET\", url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/requests/adapters.py\", line 682, in send\n    raise ConnectionError(err, request=request)\nrequests.exceptions.ConnectionError: ('Connection aborted.', PermissionError(13, 'Permission denied'))\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 830, in main\n    process()\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 820, in process\n    out_iter = func(split_index, iterator)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/pyspark/rdd.py\", line 5314, in func\n    return f(iterator)\n           ^^^^^^^^^^^\n  File \"/tmp/ipykernel_3595264/14439956.py\", line 10, in start_triton\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/client.py\", line 94, in from_env\n    return cls(\n           ^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/client.py\", line 45, in __init__\n    self.api = APIClient(*args, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/api/client.py\", line 207, in __init__\n    self._version = self._retrieve_server_version()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/rishi/anaconda3/envs/rapids-24.08/lib/python3.11/site-packages/docker/api/client.py\", line 230, in _retrieve_server_version\n    raise DockerException(\ndocker.errors.DockerException: Error while fetching server API version: ('Connection aborted.', PermissionError(13, 'Permission denied'))\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:561)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:767)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:749)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:514)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1022)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2303)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:2163)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2263)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2328)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1022)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1021)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n"
     ]
    }
   ],
   "source": [
    "num_executors = 1\n",
    "triton_models_dir = \"{}/models\".format(os.getcwd())\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:22.07-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"64M\",\n",
    "            volumes={triton_models_dir: {\"bind\": \"/models\", \"mode\": \"ro\"}}\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        ready = False\n",
    "        while not ready:\n",
    "            try:\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                time.sleep(5)\n",
    "            \n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a4362d-7514-4b84-b238-f704a97e1e72",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ab94d4d1-dac6-4474-9eb0-59478aa98f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet(\"fashion_mnist_1\")\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "12b5f2fc-52e9-428a-b683-6ab1b639aa24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('data', ArrayType(FloatType(), True), True)])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "960657d0-31c9-4df6-8eb8-ac3d23137f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool8),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name()].astype(np_types[i.datatype()]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        \n",
    "        if len(model_meta.outputs) > 1:\n",
    "            # return dictionary of numpy arrays\n",
    "            return {o.name: response.as_numpy(o.name) for o in model_meta.outputs}\n",
    "        else:\n",
    "            # return single numpy array\n",
    "            return response.as_numpy(model_meta.outputs[0].name)\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0262fd4a-9845-44b9-8c75-1c105e7deeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = predict_batch_udf(partial(triton_fn, triton_uri=\"localhost:8001\", model_name=\"fashion_mnist\"),\n",
    "                          input_tensor_shapes=[[784]],\n",
    "                          return_type=ArrayType(FloatType()),\n",
    "                          batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc5f6baa-052e-4b89-94b6-4821cf01952a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 491 ms, sys: 60.7 ms, total: 551 ms\n",
      "Wall time: 1.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(struct(df.columns))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a85dea35-e41d-482d-8a8f-52d3c108f038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 817 ms, sys: 89 ms, total: 906 ms\n",
      "Wall time: 1.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*df.columns)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bc3f0dbe-c52b-41d6-8097-8cebaa5ee5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 460 ms, sys: 105 ms, total: 565 ms\n",
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*[col(c) for c in df.columns])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a26690a-9dc4-4c36-9904-568d73e2be3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ab2fe42f-a072-4370-bac2-52fd95363530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a0608fff-7cfb-489e-96c9-8e1d92e57562",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de2664-3d60-487b-90da-6d0f3b8b9203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
